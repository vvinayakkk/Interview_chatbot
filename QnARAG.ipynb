{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers huggingface_hub -q","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-27T14:17:13.581626Z","iopub.execute_input":"2024-09-27T14:17:13.582306Z","iopub.status.idle":"2024-09-27T14:17:27.622214Z","shell.execute_reply.started":"2024-09-27T14:17:13.582261Z","shell.execute_reply":"2024-09-27T14:17:27.621004Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import login\n\n# Replace 'your_hf_token' with the token you got from Hugging Face\nlogin(token='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')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-27T14:17:27.624447Z","iopub.execute_input":"2024-09-27T14:17:27.624816Z","iopub.status.idle":"2024-09-27T14:17:28.376800Z","shell.execute_reply.started":"2024-09-27T14:17:27.624781Z","shell.execute_reply":"2024-09-27T14:17:28.375840Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer\n\n# Load the Falcon 7B model and tokenizer\nmodel_name = \"tiiuae/falcon-7b-instruct\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(model_name)\n\n# Generate function\ndef generate_question(prompt, max_length=200):\n    inputs = tokenizer(prompt, return_tensors=\"pt\")\n    outputs = model.generate(**inputs, max_length=max_length, do_sample=True, top_k=50, top_p=0.95)\n    question = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    return question\n","metadata":{"execution":{"iopub.status.busy":"2024-09-27T14:17:28.377942Z","iopub.execute_input":"2024-09-27T14:17:28.378259Z","iopub.status.idle":"2024-09-27T14:25:48.262767Z","shell.execute_reply.started":"2024-09-27T14:17:28.378228Z","shell.execute_reply":"2024-09-27T14:25:48.260164Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.13k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f47392076f9242b9b374e6c70964dfb8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.73M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44546ca787ac470ca4b228cb20c95041"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/281 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d2242c4de1a4247bddc974439b01434"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5733ad4ac28c4a84a2e1b0758539a5e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin.index.json:   0%|          | 0.00/16.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bea7df6f728d43b586005c942a3748e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f29baa15bb9f48d3aeb84484d6d0e022"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2821ea91266d4abba50b97efbfd937ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00002-of-00002.bin:   0%|          | 0.00/4.48G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4b9b3e07a6542c999f153ab15ba1e78"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b593b8b03904f2997e6e092fc891439"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/117 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f66c78768f0492295d87b3c100e6de1"}},"metadata":{}}]},{"cell_type":"code","source":"# Example prompt for question generation\nprompt = \"Generate a Java programming question suitable for an intermediate-level interview.\"\n\n# Generate question\ngenerated_question = generate_question(prompt)\nprint(\"Generated Question: \", generated_question)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-27T14:26:02.583569Z","iopub.execute_input":"2024-09-27T14:26:02.584538Z","iopub.status.idle":"2024-09-27T14:26:26.931472Z","shell.execute_reply.started":"2024-09-27T14:26:02.584497Z","shell.execute_reply":"2024-09-27T14:26:26.930298Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Generated Question:  Generate a Java programming question suitable for an intermediate-level interview.\nWhat is the difference between synchronous and asynchronous programming in Java?\n","output_type":"stream"}]},{"cell_type":"code","source":"# Basic function for evaluating answers based on a predefined model response\ndef evaluate_answer(candidate_answer, correct_answer):\n    if candidate_answer.strip().lower() == correct_answer.strip().lower():\n        return \"Correct!\"\n    else:\n        return \"Incorrect, try again!\"\n\n# Example use case\ncandidate_answer = \"A class is a blueprint for creating objects in Java.\"\ncorrect_answer = \"A class is a blueprint for creating objects in java.\"\nevaluation = evaluate_answer(candidate_answer, correct_answer)\nprint(\"Evaluation: \", evaluation)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-27T14:27:48.087902Z","iopub.execute_input":"2024-09-27T14:27:48.088676Z","iopub.status.idle":"2024-09-27T14:27:48.095255Z","shell.execute_reply.started":"2024-09-27T14:27:48.088629Z","shell.execute_reply":"2024-09-27T14:27:48.094156Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Evaluation:  Incorrect, try again!\n","output_type":"stream"}]},{"cell_type":"code","source":"def adjust_difficulty(previous_answer_correct):\n    if previous_answer_correct:\n        return \"Generate an advanced-level Java programming question.\"\n    else:\n        return \"Generate an easier Java programming question.\"\n\n# Example\nprevious_answer_correct = True\nnew_prompt = adjust_difficulty(previous_answer_correct)\nnew_question = generate_question(new_prompt)\nprint(\"New Question Based on Performance: \", new_question)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-27T14:28:04.917908Z","iopub.execute_input":"2024-09-27T14:28:04.918689Z","iopub.status.idle":"2024-09-27T14:28:34.996367Z","shell.execute_reply.started":"2024-09-27T14:28:04.918645Z","shell.execute_reply":"2024-09-27T14:28:34.995394Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"New Question Based on Performance:  Generate an advanced-level Java programming question.\nWhat is the difference between a stack and a queue, and how can they be implemented in Java?\n","output_type":"stream"}]},{"cell_type":"code","source":"def interview_bot():\n    # Start the interview with a medium difficulty question\n    current_prompt = \"Generate a Java programming question suitable for an intermediate-level interview.\"\n    \n    # Generate the first question\n    question = generate_question(current_prompt)\n    print(\"Interview Question: \", question)\n    \n    # Simulate a candidate answer (you can replace this with real input)\n    candidate_answer = input(\"Your Answer: \")\n    \n    # Evaluate the answer (in this case, we're using a simple evaluation)\n    correct_answer = \"This is a sample correct answer.\"  # You need a logic here to compare actual answers\n    evaluation = evaluate_answer(candidate_answer, correct_answer)\n    print(\"Evaluation: \", evaluation)\n    \n    # Adjust difficulty based on performance\n    if evaluation == \"Correct!\":\n        new_prompt = adjust_difficulty(True)\n    else:\n        new_prompt = adjust_difficulty(False)\n    \n    # Generate the next question\n    next_question = generate_question(new_prompt)\n    print(\"Next Question: \", next_question)\n\n# Run the interview chatbot\ninterview_bot()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"candidate_answer = \"\"\"\nIn Java, synchronized blocks are used for mutual exclusion, ensuring that only one thread can execute a block of code at a time. \nVolatile variables, on the other hand, ensure that the latest value of the variable is visible to all threads, but it does not guarantee thread safety.\n\"\"\"\n\n# Create a prompt that asks the model to evaluate the answer as if it were an interviewer\nprompt = f\"\"\"\nYou are a Java expert. I will provide you with a candidate's answer, and your task is to evaluate its correctness and give feedback.\n\nQuestion: What is the difference between synchronized blocks and volatile variables in Java?\n\nCandidate's Answer: {candidate_answer}\n\nPlease evaluate the answer for correctness and provide a score out of 10 along with feedback on the answer.\n\"\"\"\n\n# Tokenize and generate the response\ninputs = tokenizer(prompt, return_tensors=\"pt\")\noutputs = model.generate(**inputs, max_new_tokens=200)\n\n# Decode the response from the model\nresponse = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(response)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate_answer_and_get_next_question(candidate_answer):\n    \"\"\"Evaluates the candidate's answer and generates the next question based on the score.\"\"\"\n    \n    # Step 1: Create a prompt for evaluation\n    evaluation_prompt = f\"\"\"\n    You are a Java expert. I will provide you with a candidate's answer, and your task is to evaluate its correctness and give feedback.\n\n    Question: What is the difference between synchronized blocks and volatile variables in Java?\n\n    Candidate's Answer: {candidate_answer}\n\n    Please evaluate the answer for correctness and provide a score out of 10 along with feedback on the answer.\n    \"\"\"\n\n    # Tokenize and generate the evaluation response\n    inputs = tokenizer(evaluation_prompt, return_tensors=\"pt\")\n    evaluation_outputs = model.generate(**inputs, max_new_tokens=200)\n    evaluation_response = tokenizer.decode(evaluation_outputs[0], skip_special_tokens=True)\n    \n    # Step 2: Extract the score from the evaluation response\n  #  score_line = evaluation_response.splitlines()[0]  # First line contains the score\n  #  score = int(score_line.split(\"/\")[0].split(\": \")[1])  # Extract score as integer\n\n    # Step 3: Create a prompt for the next question based on the score\n    next_question_prompt = f\"\"\"\n    Based on the response which is this {evaluation_response} of the candidate for the previous question, you need to adjust the difficulty of the question smartly percentage wise as if you are taking an interview of a student and you need to adjust the difficulty after each level such as to test the skill level of the student\n    Please provide the next question.\n    \"\"\"\n\n    # Tokenize and generate the next question\n    inputs_next_question = tokenizer(next_question_prompt, return_tensors=\"pt\")\n    next_question_outputs = model.generate(**inputs_next_question, max_new_tokens=100)\n    next_question_response = tokenizer.decode(next_question_outputs[0], skip_special_tokens=True)\n    \n    return evaluation_response, next_question_response\n\n# Example usage\ncandidate_answer = \"\"\"\nIn Java, synchronized blocks are used for mutual exclusion, ensuring that only one thread can execute a block of code at a time. \nVolatile variables, on the other hand, ensure that the latest value of the variable is visible to all threads, but it does not guarantee thread safety.\n\"\"\"\n\n# Evaluate the answer and get the next question\nevaluation_response, next_question = evaluate_answer_and_get_next_question(candidate_answer)\n\n# Output the evaluation response and the next question\nprint(\"Evaluation Response:\\n\", evaluation_response)\nprint(\"\\nNext Question:\\n\", next_question)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize a list to store evaluation results\nevaluation_results = []\n\ndef conduct_interview():\n    \"\"\"Conducts a series of interview questions with the candidate.\"\"\"\n    \n    # Set the initial question\n    initial_question = \"What is the difference between synchronized blocks and volatile variables in Java?\"\n    current_question = initial_question\n    \n    for i in range(10):  # Loop for 10 questions\n        print(f\"Question {i + 1}: {current_question}\")\n        \n        # Get the candidate's answer (simulate this; in a real scenario, you'd collect user input)\n        candidate_answer = input(\"Your answer: \")\n\n        # Step 1: Create a prompt for evaluation\n        evaluation_prompt = f\"\"\"\n        You are a Java expert. I will provide you with a candidate's answer, and your task is to evaluate its correctness and give feedback.\n\n        Question: {current_question}\n\n        Candidate's Answer: {candidate_answer}\n\n        Please evaluate the answer for correctness and provide a score out of 10 along with feedback on the answer.\n        \"\"\"\n\n        # Tokenize and generate the evaluation response\n        inputs = tokenizer(evaluation_prompt, return_tensors=\"pt\")\n        evaluation_outputs = model.generate(**inputs, max_new_tokens=200)\n        evaluation_response = tokenizer.decode(evaluation_outputs[0], skip_special_tokens=True)\n\n        # Store the evaluation results\n        evaluation_results.append(evaluation_response)\n\n        # Step 2: Create a prompt for the next question based on the evaluation response\n        next_question_prompt = f\"\"\"\n        Based on the candidate's response which is this: {evaluation_response} to the previous question, \n        you need to adjust the difficulty of the next question smartly percentage-wise as if you are conducting a proper interview.\n        Please provide the next question.\n        \"\"\"\n\n        # Tokenize and generate the next question\n        inputs_next_question = tokenizer(next_question_prompt, return_tensors=\"pt\")\n        next_question_outputs = model.generate(**inputs_next_question, max_new_tokens=100)\n        next_question_response = tokenizer.decode(next_question_outputs[0], skip_special_tokens=True)\n\n        # Update the current question for the next iteration\n        current_question = next_question_response\n\n    # After all questions, provide an overall evaluation\n    overall_evaluation_prompt = f\"\"\"\n    Based on the evaluations from the following answers:\n    {evaluation_results}\n    Please provide an overall evaluation including strengths, weaknesses, and suggestions for improvement.\n    \"\"\"\n\n    # Tokenize and generate the overall evaluation\n    inputs_overall_evaluation = tokenizer(overall_evaluation_prompt, return_tensors=\"pt\")\n    overall_evaluation_outputs = model.generate(**inputs_overall_evaluation, max_new_tokens=300)\n    overall_evaluation_response = tokenizer.decode(overall_evaluation_outputs[0], skip_special_tokens=True)\n    \n    return overall_evaluation_response\n\n# Conduct the interview and get the overall evaluation\nfinal_evaluation = conduct_interview()\n\n# Output the final evaluation\nprint(\"\\nFinal Evaluation:\\n\", final_evaluation)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install torch torchvision torchaudio\n\n# Install the Hugging Face Transformers library\n!pip install transformers\n\n# Install Sentence-Transformers for embedding generation\n!pip install sentence-transformers\n\n# Install scikit-learn for similarity computation\n!pip install scikit-learn\n\n# Install numpy for numerical operations\n!pip install numpy","metadata":{"execution":{"iopub.status.busy":"2024-09-27T15:41:13.744563Z","iopub.execute_input":"2024-09-27T15:41:13.744981Z","iopub.status.idle":"2024-09-27T15:42:11.578317Z","shell.execute_reply.started":"2024-09-27T15:41:13.744942Z","shell.execute_reply":"2024-09-27T15:42:11.577116Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.19.0)\nRequirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (10.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.44.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nCollecting sentence-transformers\n  Downloading sentence_transformers-3.1.1-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.44.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.4)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.4.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.14.1)\nRequirement already satisfied: huggingface-hub>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.25.0)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (10.3.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (2024.5.15)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (0.19.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.19.3->sentence-transformers) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\nDownloading sentence_transformers-3.1.1-py3-none-any.whl (245 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.3/245.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-3.1.1\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.14.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.4)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Import necessary libraries\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForCausalLM\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sentence_transformers import SentenceTransformer\nimport numpy as np\n\n# Step 1: Load a Sentence Transformer model for embeddings (you can replace this with a lighter model like MiniLM if needed)\nembedding_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"  # Lightweight model suitable for limited memory environments\nembedding_model = SentenceTransformer(embedding_model_name)\n\n# Step 2: Load a smaller language model (for generating feedback and question refinement)\n# Choose a lighter model such as distilGPT-2 to conserve resources\nfeedback_model_name = \"distilgpt2\"\nfeedback_tokenizer = AutoTokenizer.from_pretrained(feedback_model_name)\nfeedback_model = AutoModelForCausalLM.from_pretrained(feedback_model_name)\n\n# Step 3: Define the structured Java corpus based on difficulty levels (0-100%)\n# Step 3: Define the structured Java corpus based on difficulty levels (0-100%)\njava_corpus_difficulty = {\n    '0-10': \"\"\"\n    Java is an object-oriented programming language. It was developed by Sun Microsystems and later acquired by Oracle Corporation. \n    It is widely used for building various types of applications like desktop, web, and mobile applications. \n    The primary concepts in Java include classes, objects, variables, and methods. \n    Java code is compiled into bytecode, which runs on the Java Virtual Machine (JVM). This makes Java platform-independent.\n    \"\"\",\n    \n    '10-20': \"\"\"\n    Java supports basic data types like int, double, char, and boolean. \n    It also has non-primitive data types like strings, arrays, and classes.\n    Java uses classes to define the structure of objects, and these classes contain fields (attributes) and methods (functions). \n    Objects are instances of classes, and they are created using the `new` keyword.\n    \"\"\",\n    \n    '20-30': \"\"\"\n    Java supports object-oriented principles like inheritance, encapsulation, abstraction, and polymorphism.\n    - Inheritance allows one class to inherit the fields and methods of another class using the `extends` keyword.\n    - Encapsulation ensures that the internal state of an object is hidden from the outside using private fields and public methods.\n    - Abstraction allows you to define complex systems using abstract classes and interfaces.\n    - Polymorphism enables methods to be used in different ways, depending on the object type.\n    \"\"\",\n    \n    '30-40': \"\"\"\n    In Java, constructors are special methods used to initialize new objects. \n    A constructor has the same name as the class and does not have a return type. \n    There are two types of constructors: \n    - Default Constructor: Provided by the compiler if no constructor is defined.\n    - Parameterized Constructor: Takes arguments to initialize fields of the class.\n    Java also supports method overloading, where multiple methods have the same name but different parameter lists.\n    \"\"\",\n    \n    '40-50': \"\"\"\n    Java has several control structures like loops and conditional statements:\n    - `if`, `else if`, `else` are used for decision-making.\n    - `for`, `while`, and `do-while` loops are used for iteration.\n    Java also has switch statements for handling multiple conditions.\n    Exceptions in Java are used for error handling. The `try`, `catch`, and `finally` blocks are used to catch and handle exceptions.\n    \"\"\",\n    \n    '50-60': \"\"\"\n    Java collections framework provides various data structures for managing groups of objects, like `ArrayList`, `LinkedList`, `HashSet`, and `HashMap`.\n    - `ArrayList` is a resizable array that can hold elements dynamically.\n    - `LinkedList` stores elements in a doubly-linked list.\n    - `HashSet` is used to store unique elements and does not maintain insertion order.\n    - `HashMap` stores key-value pairs and allows retrieval based on keys.\n    Java's `Collections` utility class provides several methods like sorting and searching.\n    \"\"\",\n    \n    '60-70': \"\"\"\n    Threads in Java allow for concurrent programming. The `Thread` class and `Runnable` interface are used to create and run threads.\n    The `synchronized` keyword ensures mutual exclusion, allowing only one thread to access a block of code at a time.\n    The `volatile` keyword ensures that changes to a variable are visible to all threads.\n    Java provides thread lifecycle methods like `start()`, `run()`, `sleep()`, and `join()`.\n    \"\"\",\n    \n    '70-80': \"\"\"\n    Java supports file handling using the `File` class, along with `FileInputStream` and `FileOutputStream`.\n    - `FileInputStream` is used to read data from files, and `FileOutputStream` is used to write data to files.\n    Java provides `BufferedReader` and `BufferedWriter` for efficient reading and writing of text files.\n    Java's `try-with-resources` statement ensures that files are closed properly after use.\n    \"\"\",\n    \n    '80-90': \"\"\"\n    Advanced Java features include:\n    - Reflection: Allows a Java program to introspect and manipulate the properties of objects at runtime using the `java.lang.reflect` package.\n    - Annotations: Provide metadata information to the compiler, and they can be used for code generation and runtime processing.\n    - Generics: Enable type safety by allowing parameterized types. Example: `List<String>` ensures that only strings can be added to the list.\n    \"\"\",\n    \n    '90-100': \"\"\"\n    Java Memory Management:\n    - Java uses automatic garbage collection to manage memory. The `Garbage Collector` (GC) reclaims memory used by unreachable objects.\n    - The JVM memory is divided into different regions: Heap, Stack, and Method Area.\n    - `Heap Memory` is used to store objects and class instances, while `Stack Memory` is used for method execution and local variables.\n    Java provides tools like `jvisualvm` and `jconsole` for monitoring memory usage and optimizing performance.\n    \"\"\"\n}\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-27T15:42:18.400255Z","iopub.execute_input":"2024-09-27T15:42:18.400799Z","iopub.status.idle":"2024-09-27T15:42:44.470007Z","shell.execute_reply.started":"2024-09-27T15:42:18.400746Z","shell.execute_reply":"2024-09-27T15:42:44.469099Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0901da664d44d37b37a43c12b96734c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e8d0d0ec56e4b5bba095c710dab1e4a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"693df05761ab4993995c0eed3f4a8b80"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abe776020727452baaf5835f80b0530e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16cb79759b4540a5ad2fb273520ac938"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d601e7d7006463bbc84bd1165bb8fd6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ccc8fe9937c4013805765582568d96b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eabb62dcefc74305a952cdf3ffc3125a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e555a393a7a4b27a6bb51ed842571b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e318e8e8a55435395d5a829543a57a6"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdd615fd57094c5897e8e0dd2564fb66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58db328f71c64e5a90c42a6e52f364a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e65f7ca8b6194c35935d1621ef6f6c1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24df8b6db91743e9babf591b95392aa4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a20b22cd389147cfb2efb3202e9395cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34288da846ad4c13850a6f0c38786fda"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"136027346eb94b1997c70ee3309ef152"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"478b3e0547344295acea8e4074c5cc6b"}},"metadata":{}}]},{"cell_type":"code","source":"# Step 2: Define a function to retrieve context based on the current difficulty level\ndef retrieve_context_from_difficulty(query, difficulty_level, corpus_dict, top_n=2):\n    # Retrieve sentences from the specified difficulty level of the corpus\n    relevant_corpus = corpus_dict[difficulty_level]\n    sentences = relevant_corpus.split('. ')\n    relevant_context = retrieve_relevant_sentences(query, corpus_embeddings, sentences, top_n=top_n)\n    return ' '.join(relevant_context)\n\n# Step 3: Function to interact with the smaller model for generating feedback and difficulty adjustment\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\n# Use a smaller GPT-2 variant for generating feedback\nfeedback_model_name = \"distilgpt2\"  # A lighter version of GPT-2 to reduce resource consumption\nfeedback_tokenizer = AutoTokenizer.from_pretrained(feedback_model_name)\nfeedback_model = AutoModelForCausalLM.from_pretrained(feedback_model_name)\n\ndef generate_feedback_with_difficulty(candidate_answer, question, similarity_score, difficulty_level):\n    # Create a prompt with the candidate's answer, similarity score, and original question\n    feedback_prompt = f\"\"\"\n    You are a Java expert. Given the following information, provide feedback and the next question's difficulty level:\n\n    Question: {question}\n    Candidate's Answer: {candidate_answer}\n    Similarity Score: {similarity_score}/10\n\n    Based on this score and the quality of the answer, provide feedback. Also, recommend the next question's difficulty level (0-10%) based on the candidate's skill.\n    \"\"\"\n\n    # Tokenize and generate the feedback response\n    inputs = feedback_tokenizer(feedback_prompt, return_tensors=\"pt\")\n    feedback_outputs = feedback_model.generate(**inputs, max_new_tokens=150)\n    feedback_response = feedback_tokenizer.decode(feedback_outputs[0], skip_special_tokens=True)\n\n    # Extract difficulty level and feedback from the response\n    feedback_lines = feedback_response.splitlines()\n    feedback = feedback_lines[0]  # Assume the first line is the feedback\n    recommended_difficulty = feedback_lines[-1]  # Assume the last line contains the difficulty recommendation\n\n    return feedback, recommended_difficulty\n\n# Step 4: Function to determine the next question based on recommended difficulty and topic coverage\ndef generate_next_question(candidate_answer, question, corpus_dict, corpus_embeddings, sentences, initial_difficulty='0-10'):\n    # Step 4.1: Evaluate the candidate's answer using the current difficulty level\n    similarity_score, evaluation_response, context_used = evaluate_answer(candidate_answer, corpus_embeddings, sentences)\n    \n    # Step 4.2: Use a smaller model to get feedback and recommend the next difficulty\n    feedback, recommended_difficulty = generate_feedback_with_difficulty(candidate_answer, question, similarity_score, initial_difficulty)\n\n    # Step 4.3: Select the next question from the corpus based on the new difficulty\n    next_question_context = retrieve_context_from_difficulty(question, recommended_difficulty, corpus_dict)\n    next_question = f\"Next question for difficulty level {recommended_difficulty}: {next_question_context}\"\n\n    return feedback, next_question\n\n# Example usage:\ncandidate_answer = \"\"\"\nIn Java, synchronized blocks are used for mutual exclusion, ensuring that only one thread can execute a block of code at a time. \nVolatile variables, on the other hand, ensure that the latest value of the variable is visible to all threads, but it does not guarantee thread safety.\n\"\"\"\ninitial_question = \"What is the difference between synchronized blocks and volatile variables in Java?\"\n\n# Generate feedback and the next question\nfeedback, next_question = generate_next_question(candidate_answer, initial_question, java_corpus_difficulty, corpus_embeddings, sentences)\n\n# Output the feedback and the next question\nprint(\"Feedback:\\n\", feedback)\nprint(\"\\nNext Question:\\n\", next_question)","metadata":{"execution":{"iopub.status.busy":"2024-09-27T15:42:52.652775Z","iopub.execute_input":"2024-09-27T15:42:52.653466Z","iopub.status.idle":"2024-09-27T15:42:53.593327Z","shell.execute_reply.started":"2024-09-27T15:42:52.653426Z","shell.execute_reply":"2024-09-27T15:42:53.591879Z"},"trusted":true},"execution_count":5,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[5], line 63\u001b[0m\n\u001b[1;32m     60\u001b[0m initial_question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is the difference between synchronized blocks and volatile variables in Java?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Generate feedback and the next question\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m feedback, next_question \u001b[38;5;241m=\u001b[39m generate_next_question(candidate_answer, initial_question, java_corpus_difficulty, \u001b[43mcorpus_embeddings\u001b[49m, sentences)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Output the feedback and the next question\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeedback:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, feedback)\n","\u001b[0;31mNameError\u001b[0m: name 'corpus_embeddings' is not defined"],"ename":"NameError","evalue":"name 'corpus_embeddings' is not defined","output_type":"error"}]},{"cell_type":"code","source":"# Install necessary libraries (uncomment if not already installed)\n# !pip install torch torchvision torchaudio transformers sentence-transformers scikit-learn numpy\n\n# Import required libraries\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport numpy as np\n\n# Define and load models\n# Use a smaller model like 'distilgpt2' for generating feedback and questions\nquestion_model_name = 'distilgpt2'\nembedding_model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n\n# Initialize the language model for question generation and feedback\ntokenizer = AutoTokenizer.from_pretrained(question_model_name)\nquestion_model = AutoModelForCausalLM.from_pretrained(question_model_name)\n\n# Initialize the embedding model for similarity calculation\nembedding_model = SentenceTransformer(embedding_model_name)\n\n# Set the device to CPU (you can use GPU if available)\ndevice = torch.device(\"cpu\")\nquestion_model.to(device)\n\njava_corpus_difficulty = {\n    '0-10': \"\"\"\n    Java is an object-oriented programming language. It was developed by Sun Microsystems and later acquired by Oracle Corporation. \n    It is widely used for building various types of applications like desktop, web, and mobile applications. \n    The primary concepts in Java include classes, objects, variables, and methods. \n    Java code is compiled into bytecode, which runs on the Java Virtual Machine (JVM). This makes Java platform-independent.\n    \"\"\",\n    \n    '10-20': \"\"\"\n    Java supports basic data types like int, double, char, and boolean. \n    It also has non-primitive data types like strings, arrays, and classes.\n    Java uses classes to define the structure of objects, and these classes contain fields (attributes) and methods (functions). \n    Objects are instances of classes, and they are created using the `new` keyword.\n    \"\"\",\n    \n    '20-30': \"\"\"\n    Java supports object-oriented principles like inheritance, encapsulation, abstraction, and polymorphism.\n    - Inheritance allows one class to inherit the fields and methods of another class using the `extends` keyword.\n    - Encapsulation ensures that the internal state of an object is hidden from the outside using private fields and public methods.\n    - Abstraction allows you to define complex systems using abstract classes and interfaces.\n    - Polymorphism enables methods to be used in different ways, depending on the object type.\n    \"\"\",\n    \n    '30-40': \"\"\"\n    In Java, constructors are special methods used to initialize new objects. \n    A constructor has the same name as the class and does not have a return type. \n    There are two types of constructors: \n    - Default Constructor: Provided by the compiler if no constructor is defined.\n    - Parameterized Constructor: Takes arguments to initialize fields of the class.\n    Java also supports method overloading, where multiple methods have the same name but different parameter lists.\n    \"\"\",\n    \n    '40-50': \"\"\"\n    Java has several control structures like loops and conditional statements:\n    - `if`, `else if`, `else` are used for decision-making.\n    - `for`, `while`, and `do-while` loops are used for iteration.\n    Java also has switch statements for handling multiple conditions.\n    Exceptions in Java are used for error handling. The `try`, `catch`, and `finally` blocks are used to catch and handle exceptions.\n    \"\"\",\n    \n    '50-60': \"\"\"\n    Java collections framework provides various data structures for managing groups of objects, like `ArrayList`, `LinkedList`, `HashSet`, and `HashMap`.\n    - `ArrayList` is a resizable array that can hold elements dynamically.\n    - `LinkedList` stores elements in a doubly-linked list.\n    - `HashSet` is used to store unique elements and does not maintain insertion order.\n    - `HashMap` stores key-value pairs and allows retrieval based on keys.\n    Java's `Collections` utility class provides several methods like sorting and searching.\n    \"\"\",\n    \n    '60-70': \"\"\"\n    Threads in Java allow for concurrent programming. The `Thread` class and `Runnable` interface are used to create and run threads.\n    The `synchronized` keyword ensures mutual exclusion, allowing only one thread to access a block of code at a time.\n    The `volatile` keyword ensures that changes to a variable are visible to all threads.\n    Java provides thread lifecycle methods like `start()`, `run()`, `sleep()`, and `join()`.\n    \"\"\",\n    \n    '70-80': \"\"\"\n    Java supports file handling using the `File` class, along with `FileInputStream` and `FileOutputStream`.\n    - `FileInputStream` is used to read data from files, and `FileOutputStream` is used to write data to files.\n    Java provides `BufferedReader` and `BufferedWriter` for efficient reading and writing of text files.\n    Java's `try-with-resources` statement ensures that files are closed properly after use.\n    \"\"\",\n    \n    '80-90': \"\"\"\n    Advanced Java features include:\n    - Reflection: Allows a Java program to introspect and manipulate the properties of objects at runtime using the `java.lang.reflect` package.\n    - Annotations: Provide metadata information to the compiler, and they can be used for code generation and runtime processing.\n    - Generics: Enable type safety by allowing parameterized types. Example: `List<String>` ensures that only strings can be added to the list.\n    \"\"\",\n    \n    '90-100': \"\"\"\n    Java Memory Management:\n    - Java uses automatic garbage collection to manage memory. The `Garbage Collector` (GC) reclaims memory used by unreachable objects.\n    - The JVM memory is divided into different regions: Heap, Stack, and Method Area.\n    - `Heap Memory` is used to store objects and class instances, while `Stack Memory` is used for method execution and local variables.\n    Java provides tools like `jvisualvm` and `jconsole` for monitoring memory usage and optimizing performance.\n    \"\"\"\n}\n# Function to get the corpus text based on difficulty level\ndef get_corpus_by_difficulty(difficulty_level):\n    \"\"\"Returns the corpus text for a given difficulty level.\"\"\"\n    if difficulty_level in java_corpus_difficulty:\n        return java_corpus_difficulty[difficulty_level]\n    else:\n        return java_corpus_difficulty['0-10']  # Default to '0-10' if the level is not found\n\n# Function to get the similarity score between the candidate's answer and the reference text\ndef get_similarity_score(candidate_answer, reference_text):\n    \"\"\"Calculates the similarity score between the candidate's answer and the reference text.\"\"\"\n    # Create embeddings for the candidate's answer and reference text\n    candidate_embedding = embedding_model.encode([candidate_answer])\n    reference_embedding = embedding_model.encode([reference_text])\n\n    # Calculate the cosine similarity score\n    similarity_score = cosine_similarity(candidate_embedding, reference_embedding)[0][0]\n    return similarity_score\n\n# Function to evaluate the answer, provide feedback, and suggest the next question\ndef evaluate_answer_and_get_next_question(candidate_answer, current_question, difficulty_level):\n    \"\"\"\n    Evaluates the candidate's answer and generates the next question based on the feedback.\n\n    Parameters:\n    - candidate_answer (str): The answer provided by the candidate.\n    - current_question (str): The current question that the candidate answered.\n    - difficulty_level (str): Current difficulty level of the question (e.g., '0-10').\n\n    Returns:\n    - evaluation_response (str): Feedback on the candidate's answer.\n    - next_question (str): The next question generated based on the evaluation.\n    - new_difficulty_level (str): The adjusted difficulty level for the next question.\n    \"\"\"\n    # Step 1: Calculate the similarity score between the candidate's answer and the reference text\n    reference_text = get_corpus_by_difficulty(difficulty_level)\n    similarity_score = get_similarity_score(candidate_answer, reference_text)\n    \n    # Step 2: Use the similarity score to get a feedback score\n    # Assuming a simple heuristic: 0.0 to 1.0 similarity corresponds to 0-10 score range\n    feedback_score = round(similarity_score * 10, 2)\n\n    # Step 3: Create a prompt for generating feedback based on the candidate's answer and score\n    feedback_prompt = f\"\"\"\n    You are a Java expert. I will provide you with a candidate's answer, the similarity score, and the previous question. \n    Your task is to evaluate the answer's correctness, taking into account the similarity score, and provide feedback.\n\n    Question: {current_question}\n    Candidate's Answer: {candidate_answer}\n    Similarity Score: {similarity_score}\n    Feedback Score: {feedback_score} / 10\n\n    Please provide detailed feedback on the answer and suggestions for improvement.\n    \"\"\"\n\n    # Generate the feedback response using the language model\n    inputs_feedback = tokenizer(feedback_prompt, return_tensors=\"pt\").to(device)\n    feedback_outputs = question_model.generate(**inputs_feedback, max_new_tokens=200)\n    evaluation_response = tokenizer.decode(feedback_outputs[0], skip_special_tokens=True)\n\n    # Step 4: Adjust the difficulty level based on the feedback score\n    # Use percentage ranges to define difficulty levels (e.g., 0-10%, 10-20%, etc.)\n    difficulty_level_float = int(difficulty_level.split(\"-\")[0])  # Convert difficulty range start to integer\n    if feedback_score < 3:  # Low score, reduce difficulty\n        new_difficulty_level_float = max(difficulty_level_float - 10, 0)  # Decrease by 10%, but not below 0%\n    elif feedback_score > 7:  # High score, increase difficulty\n        new_difficulty_level_float = min(difficulty_level_float + 10, 100)  # Increase by 10%, but not above 100%\n    else:\n        new_difficulty_level_float = difficulty_level_float  # Keep the same difficulty level if the score is moderate\n\n    # Convert new difficulty level float to range string (e.g., '10-20')\n    new_difficulty_level = f\"{new_difficulty_level_float}-{new_difficulty_level_float + 10}\"\n\n    # Step 5: Create a prompt for generating the next question based on the adjusted difficulty level\n    next_question_prompt = f\"\"\"\n    Based on the evaluation response: \"{evaluation_response}\" and the adjusted difficulty level of {new_difficulty_level}%, \n    generate the next Java question for the candidate, ensuring it matches the current difficulty level and covers diverse topics.\n    \"\"\"\n\n    # Generate the next question using the language model\n    inputs_next_question = tokenizer(next_question_prompt, return_tensors=\"pt\").to(device)\n    next_question_outputs = question_model.generate(**inputs_next_question, max_new_tokens=100)\n    next_question_response = tokenizer.decode(next_question_outputs[0], skip_special_tokens=True)\n    \n    return evaluation_response, next_question_response, new_difficulty_level\n\n# Example usage\n# Candidate's answer to a sample question\ncandidate_answer = \"\"\"\nIn Java, synchronized blocks are used for mutual exclusion, ensuring that only one thread can execute a block of code at a time. \nVolatile variables, on the other hand, ensure that the latest value of the variable is visible to all threads, but it does not guarantee thread safety.\n\"\"\"\ncurrent_question = \"What is the difference between synchronized blocks and volatile variables in Java?\"\ninitial_difficulty_level = '50-60'  # Assuming a medium difficulty level to start\n\n# Evaluate the answer and get the next question\nevaluation_response, next_question, new_difficulty_level = evaluate_answer_and_get_next_question(\n    candidate_answer, current_question, initial_difficulty_level\n)\n\n# Output the evaluation response, the next question, and the new difficulty level\nprint(\"Evaluation Response:\\n\", evaluation_response)\nprint(\"\\nNext Question:\\n\", next_question)\nprint(\"\\nNew Difficulty Level:\\n\", new_difficulty_level)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-27T15:51:55.668800Z","iopub.execute_input":"2024-09-27T15:51:55.669264Z","iopub.status.idle":"2024-09-27T15:52:05.346895Z","shell.execute_reply.started":"2024-09-27T15:51:55.669226Z","shell.execute_reply":"2024-09-27T15:52:05.345920Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45d3b171049d4117aedaab23f72b174f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47b41d643312489dbca54be16df66ea6"}},"metadata":{}},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Evaluation Response:\n \n    You are a Java expert. I will provide you with a candidate's answer, the similarity score, and the previous question. \n    Your task is to evaluate the answer's correctness, taking into account the similarity score, and provide feedback.\n\n    Question: What is the difference between synchronized blocks and volatile variables in Java?\n    Candidate's Answer: \nIn Java, synchronized blocks are used for mutual exclusion, ensuring that only one thread can execute a block of code at a time. \nVolatile variables, on the other hand, ensure that the latest value of the variable is visible to all threads, but it does not guarantee thread safety.\n\n    Similarity Score: 0.337144672870636\n    Feedback Score: 3.37 / 10\n\n    Please provide detailed feedback on the answer and suggestions for improvement.\n                                                                                                                                                                                                            \n\nNext Question:\n \n    Based on the evaluation response: \"\n    You are a Java expert. I will provide you with a candidate's answer, the similarity score, and the previous question. \n    Your task is to evaluate the answer's correctness, taking into account the similarity score, and provide feedback.\n\n    Question: What is the difference between synchronized blocks and volatile variables in Java?\n    Candidate's Answer: \nIn Java, synchronized blocks are used for mutual exclusion, ensuring that only one thread can execute a block of code at a time. \nVolatile variables, on the other hand, ensure that the latest value of the variable is visible to all threads, but it does not guarantee thread safety.\n\n    Similarity Score: 0.337144672870636\n    Feedback Score: 3.37 / 10\n\n    Please provide detailed feedback on the answer and suggestions for improvement.\n                                                                                                                                                                                                            \" and the adjusted difficulty level of 50-60%, \n    generate the next Java question for the candidate, ensuring it matches the current difficulty level and covers diverse topics.\n                                                                                                        \n\nNew Difficulty Level:\n 50-60\n","output_type":"stream"}]},{"cell_type":"code","source":"# Import required libraries\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# Define and load models\nquestion_model_name = 'tiiuae/falcon-7b'  # Using Falcon 7B model\nembedding_model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n\n# Initialize the language model for question generation and feedback\ntokenizer = AutoTokenizer.from_pretrained(question_model_name)\nquestion_model = AutoModelForCausalLM.from_pretrained(question_model_name)\n\n# Initialize the embedding model for similarity calculation\nembedding_model = SentenceTransformer(embedding_model_name)\n\ndef calculate_similarity_score(candidate_answer, question):\n    \"\"\"Calculates the similarity score between the candidate's answer and the question.\"\"\"\n    embeddings = embedding_model.encode([candidate_answer, question])\n    similarity = cosine_similarity([embeddings[0]], [embeddings[1]])\n    return similarity[0][0]\n\ndef evaluate_answer(candidate_answer, similarity_score):\n    \"\"\"Evaluates the candidate's answer and provides qualitative feedback.\"\"\"\n    \n    evaluation_prompt = f\"\"\"\n    You are a Java expert. Evaluate the candidate's answer below and provide qualitative feedback on its correctness.\n\n    Question: What is the difference between synchronized blocks and volatile variables in Java?\n    Candidate's Answer: {candidate_answer}\n    Similarity Score: {similarity_score}\n\n    Please provide detailed feedback on the answer, explaining what is correct and what needs improvement. \n    Do not provide a numerical score.\n    \"\"\"\n\n    # Tokenize and generate the evaluation response\n    inputs = tokenizer(evaluation_prompt, return_tensors=\"pt\") # Move to GPU if available\n    evaluation_outputs = question_model.generate(**inputs, max_new_tokens=200)\n    evaluation_response = tokenizer.decode(evaluation_outputs[0], skip_special_tokens=True)\n\n    # Extract feedback from the evaluation response\n    feedback = evaluation_response.strip()  # Assuming the entire response is feedback\n\n    return feedback\n\n# Example usage\ncandidate_answer = \"\"\"\nIn Java, synchronized blocks are used for mutual exclusion, ensuring that only one thread can execute a block of code at a time. \nVolatile variables, on the other hand, ensure that the latest value of the variable is visible to all threads, but it does not guarantee thread safety.\n\"\"\"\nquestion = \"What is the difference between synchronized blocks and volatile variables in Java?\"\n\n# Calculate the similarity score\nsimilarity_score = calculate_similarity_score(candidate_answer, question)\nprint(\"Similarity Score:\", similarity_score)\n\n# Evaluate the answer to get feedback\nfeedback = evaluate_answer(candidate_answer, similarity_score)\nprint(\"Feedback:\\n\", feedback)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install torch torchvision torchaudio\n\n# Install the Hugging Face Transformers library\n!pip install transformers\n\n# Install Sentence-Transformers for embedding generation\n!pip install sentence-transformers\n\n# Install scikit-learn for similarity computation\n!pip install scikit-learn\n\n# Install numpy for numerical operations\n!pip install numpy","metadata":{"execution":{"iopub.status.busy":"2024-09-27T17:05:16.178189Z","iopub.execute_input":"2024-09-27T17:05:16.179001Z","iopub.status.idle":"2024-09-27T17:06:15.056110Z","shell.execute_reply.started":"2024-09-27T17:05:16.178964Z","shell.execute_reply":"2024-09-27T17:06:15.054960Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.19.0)\nRequirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (10.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.44.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nCollecting sentence-transformers\n  Downloading sentence_transformers-3.1.1-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.44.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.4)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.4.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.14.1)\nRequirement already satisfied: huggingface-hub>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.25.0)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (10.3.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (2024.5.15)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (0.19.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.19.3->sentence-transformers) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\nDownloading sentence_transformers-3.1.1-py3-none-any.whl (245 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.3/245.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-3.1.1\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.14.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.4)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Import required libraries\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# Load the Falcon model and tokenizer\nmodel_name = \"tiiuae/falcon-7b-instruct\"  # Adjust if you're using a smaller version\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nquestion_model = AutoModelForCausalLM.from_pretrained(model_name)  # Load the model onto the GPU\n\n# Initialize the embedding model for similarity calculation\nembedding_model_name = 'sentence-transformers/all-MiniLM-L6-v2'\nembedding_model = SentenceTransformer(embedding_model_name)\njava_corpus_difficulty = {\n    '0-10': \"\"\"\n    Java is an object-oriented programming language. It was developed by Sun Microsystems and later acquired by Oracle Corporation. \n    It is widely used for building various types of applications like desktop, web, and mobile applications. \n    The primary concepts in Java include classes, objects, variables, and methods. \n    Java code is compiled into bytecode, which runs on the Java Virtual Machine (JVM). This makes Java platform-independent.\n    \"\"\",\n    \n    '10-20': \"\"\"\n    Java supports basic data types like int, double, char, and boolean. \n    It also has non-primitive data types like strings, arrays, and classes.\n    Java uses classes to define the structure of objects, and these classes contain fields (attributes) and methods (functions). \n    Objects are instances of classes, and they are created using the `new` keyword.\n    \"\"\",\n    \n    '20-30': \"\"\"\n    Java supports object-oriented principles like inheritance, encapsulation, abstraction, and polymorphism.\n    - Inheritance allows one class to inherit the fields and methods of another class using the `extends` keyword.\n    - Encapsulation ensures that the internal state of an object is hidden from the outside using private fields and public methods.\n    - Abstraction allows you to define complex systems using abstract classes and interfaces.\n    - Polymorphism enables methods to be used in different ways, depending on the object type.\n    \"\"\",\n    \n    '30-40': \"\"\"\n    In Java, constructors are special methods used to initialize new objects. \n    A constructor has the same name as the class and does not have a return type. \n    There are two types of constructors: \n    - Default Constructor: Provided by the compiler if no constructor is defined.\n    - Parameterized Constructor: Takes arguments to initialize fields of the class.\n    Java also supports method overloading, where multiple methods have the same name but different parameter lists.\n    \"\"\",\n    \n    '40-50': \"\"\"\n    Java has several control structures like loops and conditional statements:\n    - `if`, `else if`, `else` are used for decision-making.\n    - `for`, `while`, and `do-while` loops are used for iteration.\n    Java also has switch statements for handling multiple conditions.\n    Exceptions in Java are used for error handling. The `try`, `catch`, and `finally` blocks are used to catch and handle exceptions.\n    \"\"\",\n    \n    '50-60': \"\"\"\n    Java collections framework provides various data structures for managing groups of objects, like `ArrayList`, `LinkedList`, `HashSet`, and `HashMap`.\n    - `ArrayList` is a resizable array that can hold elements dynamically.\n    - `LinkedList` stores elements in a doubly-linked list.\n    - `HashSet` is used to store unique elements and does not maintain insertion order.\n    - `HashMap` stores key-value pairs and allows retrieval based on keys.\n    Java's `Collections` utility class provides several methods like sorting and searching.\n    \"\"\",\n    \n    '60-70': \"\"\"\n    Threads in Java allow for concurrent programming. The `Thread` class and `Runnable` interface are used to create and run threads.\n    The `synchronized` keyword ensures mutual exclusion, allowing only one thread to access a block of code at a time.\n    The `volatile` keyword ensures that changes to a variable are visible to all threads.\n    Java provides thread lifecycle methods like `start()`, `run()`, `sleep()`, and `join()`.\n    \"\"\",\n    \n    '70-80': \"\"\"\n    Java supports file handling using the `File` class, along with `FileInputStream` and `FileOutputStream`.\n    - `FileInputStream` is used to read data from files, and `FileOutputStream` is used to write data to files.\n    Java provides `BufferedReader` and `BufferedWriter` for efficient reading and writing of text files.\n    Java's `try-with-resources` statement ensures that files are closed properly after use.\n    \"\"\",\n    \n    '80-90': \"\"\"\n    Advanced Java features include:\n    - Reflection: Allows a Java program to introspect and manipulate the properties of objects at runtime using the `java.lang.reflect` package.\n    - Annotations: Provide metadata information to the compiler, and they can be used for code generation and runtime processing.\n    - Generics: Enable type safety by allowing parameterized types. Example: `List<String>` ensures that only strings can be added to the list.\n    \"\"\",\n    \n    '90-100': \"\"\"\n    Java Memory Management:\n    - Java uses automatic garbage collection to manage memory. The `Garbage Collector` (GC) reclaims memory used by unreachable objects.\n    - The JVM memory is divided into different regions: Heap, Stack, and Method Area.\n    - `Heap Memory` is used to store objects and class instances, while `Stack Memory` is used for method execution and local variables.\n    Java provides tools like `jvisualvm` and `jconsole` for monitoring memory usage and optimizing performance.\n    \"\"\"\n}","metadata":{"execution":{"iopub.status.busy":"2024-09-27T17:06:15.058315Z","iopub.execute_input":"2024-09-27T17:06:15.058673Z","iopub.status.idle":"2024-09-27T17:08:25.481770Z","shell.execute_reply.started":"2024-09-27T17:06:15.058639Z","shell.execute_reply":"2024-09-27T17:08:25.480962Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.13k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78de1995b9f44d0a8d9ef7872bfb1c0f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.73M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61f613fcc813490baa2deb3246b9a45c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/281 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac5fff9229a24363beed40664970c5c0"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f94fe3c5eb34f699385d2027fdbfbcc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin.index.json:   0%|          | 0.00/16.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"143f41e63f034c909ddf1424441ee767"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"acb2d4213fc941549c22a1471c1a137c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb10540dbe6949e2b9244ba579d55286"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00002-of-00002.bin:   0%|          | 0.00/4.48G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b863c0d4a4546c6816052f7e74c75e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1fb3a89d6e1483e9b93231048df08cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/117 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7824cc50fcf54b10ad20090604b1afb6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ed0600b77c442598ae874a98bc159ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a2bbd097e154902bd327b7fa5891bfc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3cb35aeb781a485eaf85b3e47e1e5785"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84293dbba06a4c1d83c26cfb31f29a91"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d9f85b7333343b68d18f2eb6986d601"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b4c6de71f7c421c9d6bfa65f57a11dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"576702fb3a7747c1bb42befd531435df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0bab1d1a57140b295736cfb0cc6e332"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48f81c3b437144c99a28f1089a64b851"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1cdc05a3e9c47cda82b12d0bf81b406"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"220c2202905c490ba16c6cf821d736f3"}},"metadata":{}}]},{"cell_type":"code","source":"def calculate_similarity_score(candidate_answer, question):\n    \"\"\"Calculates the similarity score between the candidate's answer and the question.\"\"\"\n    embeddings = embedding_model.encode([candidate_answer, question])\n    similarity = cosine_similarity([embeddings[0]], [embeddings[1]])\n    return similarity[0][0]\ndef evaluate_answer(candidate_answer, similarity_score):\n    \"\"\"Evaluates the candidate's answer and provides qualitative feedback.\"\"\"\n    \n    evaluation_prompt = f\"\"\"\n    \n    \n     You are a Java expert. I will provide you with a candidate's answer, and your task is to evaluate its correctness and give feedback.\n\n    Question: What is the difference between synchronized blocks and volatile variables in Java?\n\n    Candidate's Answer: {candidate_answer}\n    Similarity Score: {similarity_score}\n    Please evaluate the answer for correctness and provide a score out of 10 along with feedback on the answer.\n    \n    \"\"\"\n\n    # Tokenize and generate the evaluation response\n    inputs = tokenizer(evaluation_prompt, return_tensors=\"pt\") # Move to GPU if available\n    evaluation_outputs = question_model.generate(**inputs, max_new_tokens=200)\n    evaluation_response = tokenizer.decode(evaluation_outputs[0], skip_special_tokens=True)\n\n    # Extract feedback from the evaluation response\n    feedback = evaluation_response.strip()  # Assuming the entire response is feedback\n\n    return feedback\n\ncandidate_answer = \"\"\"\nIn Java, synchronized blocks are used for mutual exclusion, ensuring that only one thread can execute a block of code at a time. \nVolatile variables, on the other hand, ensure that the latest value of the variable is visible to all threads, but it does not guarantee thread safety.\n\"\"\"\nquestion = \"What is the difference between synchronized blocks and volatile variables in Java?\"\n\n# Calculate the similarity score\nsimilarity_score = calculate_similarity_score(candidate_answer, question)\nprint(\"Similarity Score:\", similarity_score)\n\n# Evaluate the answer to get feedback\nfeedback = evaluate_answer(candidate_answer, similarity_score)\nprint(\"Feedback:\\n\", feedback)","metadata":{"execution":{"iopub.status.busy":"2024-09-27T17:08:25.483480Z","iopub.execute_input":"2024-09-27T17:08:25.484642Z","iopub.status.idle":"2024-09-27T17:12:26.940161Z","shell.execute_reply.started":"2024-09-27T17:08:25.484592Z","shell.execute_reply":"2024-09-27T17:12:26.939205Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"150c1339f89740f38eb2ef8f9e716202"}},"metadata":{}},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Similarity Score: 0.91410697\nFeedback:\n You are a Java expert. I will provide you with a candidate's answer, and your task is to evaluate its correctness and give feedback.\n\n    Question: What is the difference between synchronized blocks and volatile variables in Java?\n\n    Candidate's Answer: \nIn Java, synchronized blocks are used for mutual exclusion, ensuring that only one thread can execute a block of code at a time. \nVolatile variables, on the other hand, ensure that the latest value of the variable is visible to all threads, but it does not guarantee thread safety.\n\n    Similarity Score: 0.9141069650650024\n    Please evaluate the answer for correctness and provide a score out of 10 along with feedback on the answer.\n    \n    <p>The candidate's answer is mostly correct. Synchronized blocks are used for mutual exclusion, and volatile variables are used to ensure that the latest value of a variable is visible to all threads. However, the candidate has not provided a clear explanation of the difference between the two concepts. It would be helpful to provide more context and examples to better understand the concepts.</p>\n\n<p>The candidate's answer is mostly correct, but it could be improved with more information. The candidate has correctly identified that synchronized blocks are used for mutual exclusion, but it would be helpful to provide an example of when this would be useful. Additionally, the candidate has correctly identified that volatile variables are used to ensure the latest value of a variable is visible to all threads, but it would be helpful to provide an example of when this would be useful. Overall, the candidate's answer is mostly correct, but it could be improved with more information.</p>\n","output_type":"stream"}]},{"cell_type":"code","source":"import re\n\n\n# Extract the feedback part using regular expressions\n# Assuming feedback starts with <p> and ends with </p>\nextracted_feedback = re.findall(r'<p>(.*?)</p>', feedback)\n\n# Join the extracted feedback parts into a single string\nclean_feedback = ' '.join(extracted_feedback)\nprint(\"Question 1 is: \",question)\nprint(\"\\n\")\nprint(\"Answer given is:\",candidate_answer)\nprint(\"\\nSimilarity Score btw answer and the actual answer is:\",similarity_score)\nprint(\"\\n\")\n\n# Print the cleaned feedback\nprint(\"Extracted Feedback:\\n\", clean_feedback)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-27T17:28:28.987449Z","iopub.execute_input":"2024-09-27T17:28:28.987810Z","iopub.status.idle":"2024-09-27T17:28:28.994622Z","shell.execute_reply.started":"2024-09-27T17:28:28.987778Z","shell.execute_reply":"2024-09-27T17:28:28.993660Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Question 1 is:  What is the difference between synchronized blocks and volatile variables in Java?\n\n\nAnswer given is: \nIn Java, synchronized blocks are used for mutual exclusion, ensuring that only one thread can execute a block of code at a time. \nVolatile variables, on the other hand, ensure that the latest value of the variable is visible to all threads, but it does not guarantee thread safety.\n\n\nSimilarity Score btw answer and the actual answer is: 0.91410697\n\n\nExtracted Feedback:\n The candidate's answer is mostly correct. Synchronized blocks are used for mutual exclusion, and volatile variables are used to ensure that the latest value of a variable is visible to all threads. However, the candidate has not provided a clear explanation of the difference between the two concepts. It would be helpful to provide more context and examples to better understand the concepts. The candidate's answer is mostly correct, but it could be improved with more information. The candidate has correctly identified that synchronized blocks are used for mutual exclusion, but it would be helpful to provide an example of when this would be useful. Additionally, the candidate has correctly identified that volatile variables are used to ensure the latest value of a variable is visible to all threads, but it would be helpful to provide an example of when this would be useful. Overall, the candidate's answer is mostly correct, but it could be improved with more information.\n","output_type":"stream"}]}]}