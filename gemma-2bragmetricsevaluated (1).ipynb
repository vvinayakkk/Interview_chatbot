{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9554660,"sourceType":"datasetVersion","datasetId":5821950},{"sourceId":9937967,"sourceType":"datasetVersion","datasetId":6109709}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers\n!pip install torch\n!pip install peft  # For adapter-based fine-tuning","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install faiss-cpu  # Use faiss-gpu if you have GPU\n!pip install sentence-transformers\n!pip install pandas numpy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install nltk\n!pip install bert-score\n!pip install rouge-score\n!pip install evaluate","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install accelerate","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport faiss\nfrom sentence_transformers import SentenceTransformer\nimport torch\nimport json","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport nltk\nfrom nltk.translate.bleu_score import sentence_bleu\nfrom bert_score import score\nfrom rouge_score import rouge_scorer\nimport torch\nimport evaluate\nnltk.download('punkt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nfrom peft import PeftModel, PeftConfig\nimport os","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"access_token = \"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\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install langchain_google_genai","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_fine_tuned_model(adapter_path):\n    try:\n        \n        # Load base model and tokenizer\n        base_model_name = \"google/gemma-2b\"\n\n        # Load tokenizer\n        print(\"Loading tokenizer...\")\n        tokenizer = AutoTokenizer.from_pretrained(base_model_name,use_auth_token=access_token)\n\n        # Load base model\n        print(\"Loading base model...\")\n        base_model = AutoModelForCausalLM.from_pretrained(\n            base_model_name,\n            torch_dtype=torch.float16,  # Use float16 for efficiency\n            device_map=\"auto\",\n            use_auth_token=access_token# Automatically handle device placement\n        )\n\n        # Load the fine-tuned adapter\n        print(\"Loading fine-tuned adapter...\")\n        model = PeftModel.from_pretrained(base_model, adapter_path)\n\n        print(\"Model loaded successfully!\")\n        return model, tokenizer\n\n    except Exception as e:\n        print(f\"Error loading model: {str(e)}\")\n        return None, None","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_question(model, tokenizer, passage, topic=None, subtopic=None, difficulty=None):\n    try:\n        # Construct prompt based on available information\n        prompt_parts = [\"Generate a question based on the following information:\"]\n\n        if topic:\n            prompt_parts.append(f\"Topic: {topic}\")\n        if subtopic:\n            prompt_parts.append(f\"Subtopic: {subtopic}\")\n        if difficulty:\n            prompt_parts.append(f\"Difficulty: {difficulty}\")\n\n        prompt_parts.append(f\"Passage: {passage}\")\n        prompt_parts.append(\"Question:\")\n\n        prompt = \"\\n\".join(prompt_parts)\n\n        # Tokenize input\n        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n\n        # Generate output\n        outputs = model.generate(\n            inputs[\"input_ids\"],\n            max_length=512,\n            temperature=0.7,\n            num_return_sequences=1,\n            do_sample=True,\n            top_p=0.9,\n            top_k=50\n        )\n\n        # Decode and return the generated question\n        question = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n        # Extract just the generated question (remove the prompt)\n        question = question[len(prompt):].strip()\n\n        return question\n\n    except Exception as e:\n        print(f\"Error generating question: {str(e)}\")\n        return None","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom nltk.translate.bleu_score import sentence_bleu\nfrom bert_score import score\nfrom rouge_score import rouge_scorer\nimport nltk\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndef calculate_metrics(generated_question, reference_questions):\n    \"\"\"\n    Calculate all metrics for a generated question against multiple reference questions\n    \"\"\"\n    metrics = {}\n    \n    # Ensure reference_questions is a list of strings\n    if isinstance(reference_questions, str):\n        reference_questions = [reference_questions]\n    elif isinstance(reference_questions, list):\n        # Convert any non-string elements to strings\n        reference_questions = [str(ref) for ref in reference_questions if ref is not None]\n    else:\n        print(f\"Unexpected reference_questions type: {type(reference_questions)}\")\n        return get_zero_metrics()\n\n    if not generated_question or not reference_questions:\n        return get_zero_metrics()\n\n    try:\n        # 1. BLEU Scores\n        bleu_scores = get_bleu_scores(generated_question, reference_questions)\n        metrics.update(bleu_scores)\n\n        # 2. BERTScore\n        bert_scores = get_bert_scores(generated_question, reference_questions)\n        metrics.update(bert_scores)\n\n        # 3. ROUGE Scores\n        rouge_scores = get_rouge_scores(generated_question, reference_questions)\n        metrics.update(rouge_scores)\n\n    except Exception as e:\n        print(f\"Error in calculate_metrics: {str(e)}\")\n        return get_zero_metrics()\n\n    return metrics\n\ndef get_zero_metrics():\n    \"\"\"Return a dictionary with all metrics set to 0.0\"\"\"\n    return {\n        'BLEU-1': 0.0, 'BLEU-2': 0.0, 'BLEU-3': 0.0, 'BLEU-4': 0.0,\n        'BERTScore-P': 0.0, 'BERTScore-R': 0.0, 'BERTScore-F1': 0.0,\n        'ROUGE-1': 0.0, 'ROUGE-2': 0.0, 'ROUGE-L': 0.0\n    }\n\ndef get_bleu_scores(generated, references):\n    \"\"\"Calculate BLEU scores with proper tokenization\"\"\"\n    try:\n        # Tokenize generated question\n        generated_tokens = nltk.word_tokenize(str(generated).lower())\n        \n        # Tokenize all reference questions\n        reference_tokens = [nltk.word_tokenize(str(ref).lower()) for ref in references]\n        \n        # Calculate BLEU scores with different weights\n        weights = [\n            (1.0, 0.0, 0.0, 0.0),  # BLEU-1\n            (0.5, 0.5, 0.0, 0.0),  # BLEU-2\n            (0.33, 0.33, 0.33, 0.0),  # BLEU-3\n            (0.25, 0.25, 0.25, 0.25)  # BLEU-4\n        ]\n        \n        bleu_scores = {}\n        for i, weight in enumerate(weights, 1):\n            score = sentence_bleu(reference_tokens, generated_tokens, weights=weight)\n            bleu_scores[f'BLEU-{i}'] = score\n            \n        return bleu_scores\n        \n    except Exception as e:\n        print(f\"Error in BLEU calculation: {str(e)}\")\n        return {f'BLEU-{i}': 0.0 for i in range(1, 5)}\n\ndef get_bert_scores(generated, references):\n    \"\"\"Calculate BERTScore with proper input handling\"\"\"\n    try:\n        # Ensure inputs are strings\n        generated = str(generated)\n        references = [str(ref) for ref in references]\n        \n        # Calculate BERTScore\n        P, R, F1 = score([generated], references, lang='en', verbose=False)\n        \n        return {\n            'BERTScore-P': P.mean().item(),\n            'BERTScore-R': R.mean().item(),\n            'BERTScore-F1': F1.mean().item()\n        }\n        \n    except Exception as e:\n        print(f\"Error in BERTScore calculation: {str(e)}\")\n        return {'BERTScore-P': 0.0, 'BERTScore-R': 0.0, 'BERTScore-F1': 0.0}\n\ndef get_rouge_scores(generated, references):\n    \"\"\"Calculate ROUGE scores with proper input handling\"\"\"\n    try:\n        scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n        \n        # Ensure inputs are strings\n        generated = str(generated)\n        \n        # Calculate ROUGE scores against all references and take the maximum\n        max_scores = {\n            'ROUGE-1': 0.0,\n            'ROUGE-2': 0.0,\n            'ROUGE-L': 0.0\n        }\n        \n        for ref in references:\n            ref = str(ref)\n            scores = scorer.score(generated, ref)\n            max_scores['ROUGE-1'] = max(max_scores['ROUGE-1'], scores['rouge1'].fmeasure)\n            max_scores['ROUGE-2'] = max(max_scores['ROUGE-2'], scores['rouge2'].fmeasure)\n            max_scores['ROUGE-L'] = max(max_scores['ROUGE-L'], scores['rougeL'].fmeasure)\n            \n        return max_scores\n        \n    except Exception as e:\n        print(f\"Error in ROUGE calculation: {str(e)}\")\n        return {'ROUGE-1': 0.0, 'ROUGE-2': 0.0, 'ROUGE-L': 0.0}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PassageRetriever:\n    def __init__(self, csv_path):\n        # Load the dataset\n        self.df = pd.read_csv(csv_path)\n        \n        # Clean and preprocess the data\n        self.clean_data()\n        \n        # Initialize the embedding model\n        self.embedder = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n        \n        # Create FAISS index\n        self.setup_faiss()\n\n    def clean_data(self):\n        \"\"\"Clean and preprocess the dataset\"\"\"\n        # Convert all passages to string and clean them\n        self.df['Passage'] = self.df['Passage'].astype(str)\n        self.df['Passage'] = self.df['Passage'].apply(self.clean_text)\n        \n        # Remove rows with empty passages\n        self.df = self.df[self.df['Passage'].str.strip() != '']\n        \n        # Reset index\n        self.df = self.df.reset_index(drop=True)\n        \n        print(f\"Total valid passages after cleaning: {len(self.df)}\")\n\n    def clean_text(self, text):\n        \"\"\"Clean individual text\"\"\"\n        if pd.isna(text) or text == 'nan':\n            return ''\n        \n        # Convert to string if not already\n        text = str(text)\n        \n        # Remove excessive whitespace\n        text = ' '.join(text.split())\n        \n        return text\n\n    def setup_faiss(self):\n        try:\n            # Create embeddings for all passages\n            print(\"Creating embeddings for passages...\")\n            passages = self.df['Passage'].tolist()\n            \n            print(\"\\nFirst few passages:\")\n            for i, passage in enumerate(passages[:3]):\n                print(f\"Passage {i+1}: {passage[:100]}...\")\n            \n            embeddings_list = []\n            for i, passage in enumerate(passages):\n                try:\n                    embedding = self.embedder.encode(passage)\n                    embeddings_list.append(embedding)\n                except Exception as e:\n                    print(f\"Error encoding passage {i}: {str(e)}\")\n                    print(f\"Problematic passage: {passage[:100]}...\")\n                    embedding = np.zeros(self.embedder.get_sentence_embedding_dimension())\n                    embeddings_list.append(embedding)\n            \n            self.passage_embeddings = np.vstack(embeddings_list)\n            \n            embedding_dim = self.passage_embeddings.shape[1]\n            self.index = faiss.IndexFlatL2(embedding_dim)\n            \n            self.index.add(self.passage_embeddings.astype('float32'))\n            \n            print(f\"\\nSuccessfully created FAISS index with {len(passages)} passages\")\n            \n        except Exception as e:\n            print(f\"Error in setup_faiss: {str(e)}\")\n            raise\n\n    def get_relevant_passage(self, topic, subtopic, difficulty, k=5):  # Increased k to get more candidates\n        try:\n            # Create query from topic and subtopic\n            query = f\"{topic} {subtopic}\"\n            \n            # Get query embedding\n            query_embedding = self.embedder.encode([query])\n            \n            # Search in FAISS with increased k\n            distances, indices = self.index.search(query_embedding.astype('float32'), k)\n            \n            # Filter by difficulty and collect all matching passages\n            relevant_passages = []\n            seen_passages = set()  # To avoid duplicates\n            \n            for idx in indices[0]:\n                passage_row = self.df.iloc[idx]\n                \n                # Check if this passage matches our criteria\n                if (passage_row['Difficulty'].strip().lower() == difficulty.strip().lower() and\n                    passage_row['Topic'].strip().lower() == topic.strip().lower() and\n                    passage_row['Sub-Topic'].strip().lower() == subtopic.strip().lower()):\n                    \n                    # Create a unique key for this passage\n                    passage_key = (passage_row['Passage'], passage_row['Question'])\n                    \n                    # Only add if we haven't seen this exact passage before\n                    if passage_key not in seen_passages:\n                        seen_passages.add(passage_key)\n                        relevant_passages.append({\n                            'passage': passage_row['Passage'],\n                            'topic': passage_row['Topic'],\n                            'subtopic': passage_row['Sub-Topic'],\n                            'difficulty': passage_row['Difficulty'],\n                            'reference_questions': passage_row['Question']\n                        })\n            \n            if not relevant_passages:\n                print(f\"No passages found for {topic} - {subtopic} with difficulty {difficulty}\")\n                return None\n            \n            # Combine all reference questions for the same passage\n            if len(relevant_passages) > 1:\n                # Combine all reference questions while keeping the first passage's metadata\n                combined_passage = relevant_passages[0]\n                all_questions = [p['reference_questions'] for p in relevant_passages]\n                combined_passage['reference_questions'] = all_questions\n                return combined_passage\n            \n            return relevant_passages[0]\n            \n        except Exception as e:\n            print(f\"Error in get_relevant_passage: {str(e)}\")\n            return None","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nltk.download('punkt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate_question_generation(retriever, model, tokenizer, topics_list):\n    \"\"\"\n    Evaluate question generation for given topics using RAG\n    \"\"\"\n    results = []\n\n    for topic_info in topics_list:\n        try:\n            # Get relevant passage using RAG\n            retrieved_data = retriever.get_relevant_passage(\n                topic_info['Topic'],\n                topic_info['Sub-Topic'],\n                topic_info['Difficulty']\n            )\n            \n            if retrieved_data is None:\n                print(f\"No matching passage found for {topic_info}\")\n                continue\n\n            # Generate question\n            generated_question = generate_question(\n                model,\n                tokenizer,\n                passage=retrieved_data['passage'],\n                topic=retrieved_data['topic'],\n                subtopic=retrieved_data['subtopic'],\n                difficulty=retrieved_data['difficulty']\n)           \n            print(\"retrieved data is :\",retrieved_data)\n            print(\"GeneratedQuestion:\",generated_question)\n            if generated_question is None:\n                print(f\"Failed to generate question for {topic_info}\")\n                continue\n\n            # Calculate metrics\n            metrics = calculate_metrics(generated_question, [retrieved_data['reference_questions']])\n\n            # Store results using the correct dictionary keys\n            result = {\n                'Topic': retrieved_data['topic'],  # Note the lowercase 'topic'\n                'SubTopic': retrieved_data['subtopic'],  # Note the lowercase 'subtopic'\n                'Difficulty': retrieved_data['difficulty'],\n                'Retrieved_Passage': retrieved_data['passage'],\n                'Generated_Question': generated_question,\n                'Reference_Question': retrieved_data['reference_questions'],\n                **metrics\n            }\n            results.append(result)\n\n        except Exception as e:\n            print(f\"Error processing topic {topic_info}: {str(e)}\")\n            continue\n\n    # Return empty DataFrame if no results\n    if not results:\n        return pd.DataFrame(columns=[\n            'Topic', 'SubTopic', 'Difficulty', 'Retrieved_Passage',\n            'Generated_Question', 'Reference_Question',\n            'BLEU-1', 'BLEU-2', 'BLEU-3', 'BLEU-4',\n            'BERTScore-P', 'BERTScore-R', 'BERTScore-F1',\n            'ROUGE-1', 'ROUGE-2', 'ROUGE-L'\n        ])\n\n    return pd.DataFrame(results)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def main():\n    try:\n        # Paths\n        csv_path = \"/kaggle/input/nikahatmaam/pass_QA_topic_stopic_diff.csv\"\n        adapter_path = \"/kaggle/input/config-files\"\n\n        # Initialize retriever\n        print(\"Initializing passage retriever...\")\n        retriever = PassageRetriever(csv_path)\n        print(\"Passage is:\",retriever)\n        # Load the question generation model\n        print(\"Loading question generation model...\")\n        model, tokenizer = load_fine_tuned_model(adapter_path)\n\n        if model is None or tokenizer is None:\n            raise ValueError(\"Failed to load the question generation model\")\n\n        # Example topics to evaluate\n        topics_to_evaluate = [\n            {'Topic': 'Java Variables', 'Sub-Topic': 'Variable Declaration and Initialization', 'Difficulty': 'Easy'},\n        ]\n\n        # Run evaluation\n        print(\"Generating and evaluating questions...\")\n        results_df = evaluate_question_generation(retriever, model, tokenizer, topics_to_evaluate)\n\n        # Save results\n        results_df.to_csv('evaluation_results_with_rag.csv', index=False)\n\n        # Print summary statistics\n        if not results_df.empty:\n            print(\"\\nAverage Scores:\")\n            metrics_cols = [\n                'BLEU-1', 'BLEU-2', 'BLEU-3', 'BLEU-4',\n                'BERTScore-P', 'BERTScore-R', 'BERTScore-F1',\n                'ROUGE-1', 'ROUGE-2', 'ROUGE-L'\n            ]\n\n            for col in metrics_cols:\n                print(f\"{col}: {results_df[col].mean():.4f}\")\n\n            print(\"\\nScores by Difficulty:\")\n            print(results_df.groupby('Difficulty')[metrics_cols].mean())\n        else:\n            print(\"No results generated.\")\n\n    except Exception as e:\n        print(f\"Error in main: {str(e)}\")\n        import traceback\n        traceback.print_exc()\n\nif __name__ == \"__main__\":\n    main()","metadata":{"execution":{"iopub.status.idle":"2024-11-20T16:38:44.358804Z","shell.execute_reply.started":"2024-11-20T16:35:52.491907Z","shell.execute_reply":"2024-11-20T16:38:44.357972Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2647b9fd9cea4896ada565b504ac889b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ab5b41476304734bfbeb33b1785fbf1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"602f9c28f02e4fc1b6f05666370790d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e10d10ca635240278ede4c8ab77626fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84c63c806b2f4520bc7fbb24c26f5af1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f6c6526713d4dc0b927120d58717985"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81975582fe0b4fd885a469d15badd5a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"606fb0e2ecb7440297db77418b06b486"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b341e6e17e1c4845bc707001e26de467"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"809a074e406543369d5cb756a233e6c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6a7dfb13cca4c089c3d1b2fe586256e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d76c8d1a5feb44d4828467c5bab34cf2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93856dae674d4cb9b48f66629676b856"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fe399d0225f4dca903e8b522e20216d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e89773aa0814e5e857e94e336d274c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"772b51ad63ed4f519298cab20f4d5530"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eef4b09ba0c54aee8d5004af2a99ec16"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e04a06e371646fcadfbdfb16f95426f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54c5cb565dc7423caa99a40e173677e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5163ea89f9f145fc89fe64cb14921548"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01d4f15e09b545bcbb58c35a3b45574e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c94605b37a6486caf3056fd7f4d9196"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"985f7ca7feff43b18e3b9d7de56fd26b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a27887d9e584f4da88c2ee74afb4fdf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a320cff1480348d78b961362a9fb37be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b74c968a9be648f4a9689eada371c0bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf06dce748264a0cb3d3ba1305e4469a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cf6805a896145288f2d38fdc0d1d490"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5eeeecbb7ad49a8b7232671fd6de8c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04ecc4ad71164fcdaef6785a471533c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab78322b17ac43c39a71f486847bd472"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"750070da3ec348a2bcfe1550296b9711"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d03610f6714647f5893f93ac48bbce80"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a578eb3d51624135a9a49dca8b32e932"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"113bb652021c429e9844f156234b9369"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8104f9603cb84b0581f7467d8c35282d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ab61d8d14c34fadb9d3fe7f3edacfe0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e42d0c984bc4c94aa4cf404267e1c6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eba0fb728e58425b8f2e0406ade2b4ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b02f81e745547dd9ba71f3ef80a4313"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ddb5e4a7f6c4de794247c856ce09ea8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d24c549814df447d804f79722f3df845"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fa0a995a46745b5863e963d3bf7bca5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b1e891500a8473d8837b964b830be2b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8514a8867090427497a86c2a80eeac96"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93bbe139366c44adb0f564d161847ee2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d52fb6ab3bb44f3c8794d9e0226b944c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93216333bec34521ae9105212d5857f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7622faf5963425293d6bbd395c3d66c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3cbc3a75fe4441478147c635394eb1f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3533aa7f9624f4e93434b51bff5217b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86f5af3baa9d43c4bf40b7ad35b50266"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f365524027b46088d00befaf9eafc83"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb1fb23a37254aa4a41fdb74dbfc03ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"281515407ca441b3a61a3e49db498e54"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"146f4387f91d4ec4a36c12a96930dbae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a8c824642164c7dbaaa34ea489d009c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76091aeb3c11469ebae75fec6acdadef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e9b5f7da2e14eae9ce0134dc42a7ee4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad2b16ca04494d4a8c666bc7e589f96b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d17154d1047488d8358a3abb8e9ec4c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67bdf5ae582e432e9bc8a9d728627883"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b4143c23d434ce18d95161177898771"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5af5ebebe01640cdba3cde83c7c73b7c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b0241cc79d243f3bdcea292d510d4b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76937fca91454d96a95cbfecf93a98a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7957cbfb9f4445208bb57c9543c13e68"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3068f2ba2304a65bd7f6cfef28a729d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2af0ec9e0fd41a1846dba23a5d192f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d56b0aac9223433f9b6b108800b8522f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f19a32af876489c87e106002bd57ff1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5e5690f8c004bc386a1f482d7357c03"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61d018e93b0d44888dac8a93b6210d7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cba0f9ff09c646d099a6cc2e25eb6284"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"145093dfead844b2822b5a07d0e1e8e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fb9987c836341b79169c11bf36e770c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3d9b669357c41b8a7fdd21fed3c8b87"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1e1f41e6fa749e8824c421e4e2f01c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f90620800e246f9a5271be4db4cf142"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e63242ec1c51410e8217b3cf50f698fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ce6fa856abc4fb0bff8fd1eb0b6c91b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"291d8c7057e94d0fa6080edd773ef425"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4508911999c645a79117881fe69b1afb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"426712aba51c4349a126e319b9a68af9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de4675fcaa4641798f5cf2af76045316"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee978b3c7b7a4539a52b2ffa5fd1839c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f41c0d728cb4114bb0c1b610a7f5656"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1c330b13813481eb6e2ebcacb9346f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fa3b19a0ac14e3888b3dd52b2eee396"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a4044c7d2084318a31901e64e826147"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b0d673208b9471ba70ba11a05b20f41"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56ebd80c92d245cea6a83660e4173204"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d472176b6437495cb326be0dc67b7fc5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"681e876da4384863a415c25dd73ba73d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0a74ba4aa5f48ae82ccd0c5228faae4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8a3697c0587423fbd8cd66d1fa62423"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"908aef19beb44353aefd68a857cacd33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85e0f73e1e7445049f4802d62831f5ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"221389df829b4fb6b086216290d7125c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d08e235884a4145be6504bb484393ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2eab2b62fe074236ad7cca7b2986eb10"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2eb1c620701414684181ce4df6409f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"681ff903beb74d3c8c7318f1524378b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1118443c270a42b88771c259abac55db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5640e6b7692f461aaedafda7f77eab97"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a6bd1ecd60d43f6b0a57e9248fd0653"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aae2f16a92cd42deb5ce742aef5f99a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67a1694692144a68a9c2bae8a3e2df76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47382338895d4977bdadd7ce10d50fda"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ffef7dcc9d14f5197faa76033d88bf8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"025d93c039bd4443a7b9e15620129794"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c66d6c71438c4fad8c8e6cfb779c2a4f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1a6d9c8b45f451d8e7b5ee8b19bf6cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42fde2cb130047a0bb11206a5aa8d37c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04c6701dc7814f2a8cde74f2f2676539"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e931846f3054852a17408cc875dbf92"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d233f8e6a9304e499301e128aba4f00f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7853afbcd71a4ff6aab82d868d0a5487"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0aa3d508a2a434d8f6227ef4d9149d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4419ee13df6430cbdaac3b7abce8266"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a8f6ce152614bf7b8c27b3019890d15"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a6c5deca92748c885d41f3292d00e26"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a07d609faed4f3b99b9cc8258179648"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f430f345fc7646ef8165492afe5a4397"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b4f2973339e491595f37b1b64de00b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0b285a655384087a27695a772207b1d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c394c319c2f74bfbbd7bd95a856947d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a218d50cb854c1ea443aaca9036d223"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8778d8a60e844f47960bc80f58a7963b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec2e976662cd4b18931ccd7d4059cd89"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"987a03151d2c41f38b9d9fb9a34d8086"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5c96fa0e6b045699c1e2f2f9b890347"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbc23b7dadd74f58a8e02561367930c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff4c506aacf54962a99e48c64e1e3789"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c157abb656e4488fa03b864b92d56f97"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50c8f17d223748d7927fe4491a0dab4c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7fdd26466c4b48ad96271cf28f54e13a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88e844afa2fa48519f5d44d1fce4f3e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"404d004878dc4203bbb1cdb89ee3abfb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6b92acfb9fc4129a2cc3453638f5008"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7fb9d86d28e14e7b8b806a6dca6e7281"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e1d127b44e949818d52f18e46e5ec4b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"721b6935d2064bedb576a0ba7e6e7179"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd33902b01964e53a72117706865b8fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71dd90e914b147c391a89453f00d3922"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40024bff691d4cb2af7502e197007b61"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee2a8fd6f1f844319e26bd261f39da33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e9e0ad6c7794139b1e0dfb6d1bbe7de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f15ad97073bd459094745c5f8e1d7a18"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5d2c2451c0c408385d4398f83c8a9c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c47f3f86b650492f974fa0505289daa3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbb4c24d28474f28a405d941625c04cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"355b20f1d23947c9953fe0eadc4c98be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c9ddcad06c44759add6bee7bf6dc984"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de0d42be110b4164a95040508346469d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c27cb86e95141c996900a72ec623e80"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b1a117da3aa4c5baf08b777a692ae87"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6d2e096a82340cc895357dcf5210a84"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e70276b3e60c414792cf454a7ace3c31"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f33745a287de4208a5067059b21fe1b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da4f39aa51354ef8a42a82c9bdbb1cee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c73155edd3c44b7bae9ec476e4637a02"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08ef2c0c4b8e45cf84171b9349262535"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56f6e548b02c4eaa91015a991d4224c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2490a6d0d7864990b109ffbcc8b2eae1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"539c23041df1476784d861525e539646"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a2b869813444ae9b7020a8efb5f0556"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7caa451c6b3a43bba620b702f67d9470"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b12867c3c6ce455f91cd7991b9bea201"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d480074cd34b4d99aa0348e011a2bf43"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1e3aba1100341a1899767059184d1e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aec44337aab24f71b036529f2b0c5a69"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ea3997acbd14ad38e818d8dc10896e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a191852985374e3db5ee6bb587a4bab9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2799b93ece444eaa94c2c590a61f0ccd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5112b17b277b4cfcb01e638c055d33a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e56ce1511a04da8b9217083f789b8f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51b498e506204e14b6eca0cb2fc45959"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d2dca954ac04bfba5ed6914bf906309"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f4e643d0b1441f4922d5e3ad6df5624"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f84c2d5ba214833bf76cd5ea2ceada9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e0f550d51f94e239bcdf8986c3e86d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06d699967706401da6ba7fae9ab89fc2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccc8bfa50c7846f6ab4baffb94152b0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1809c42e7d6c4d72b158835470948ff3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da8184c91c444ec9a726095f91a9f749"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab57e2f738024c44812766ef0b6b7bb4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fb7c2f483f545d1bfd86292f22e1f84"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d8a18b94eca428a8a1cdbb38d0b3eae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"266e3232572e4c068cffa2632bc28f42"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c91a61165414b75ac991b0c59248ab8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81ce88aad2274490b8dccc4f1bf3661c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92cd01780a7743709d7026223c388181"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c0b822c307b4e3eb585227f6a102f7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"beaa0e21d16a4fa2ad3ce7c6f7306ee3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71be16f959194ff4b4c84c2c4c336be5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccb8758863de448885cbcc09b218cedd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32504233acaa467698f8075e488ee001"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdfd07e8e4d141f1910d4bf06a090000"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffb9441ff3a447368c9c30c075f7e08a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3279d06c4724b5a920441ad2478bee3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9012053d406f47b5bcdcccc14fba993c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c1198c53b21494b8d1d2ad22c0904dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e713eac87a441bb8db1de22b0dbe621"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"282aeb0059134a50a182a45f8bab883b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"592e713334f840dfb223822d82e753e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96ff6eb640d240d6a71b6c01341e9411"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb88d630d72d473689012be53f9a0901"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"718fb3b03d3e4a48b288780a1501d01b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdbbd5beb8cc434291ee82b03f630b7c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f50c5bb5eabf495b999015a2f469120e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ede2c81fcd5743cc969a89bf4fad6002"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd113f74e2264e4388adaf8c978fcdd6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f98a37567d54441a107bb7ea4df3140"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b880ac5adbf04ca5b00ce6da654f9476"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"271f93bd85474870aaead332e0941e37"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12f1348657294cba88f4593af5b7ce36"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"365fb330a4c544b4bc7bd12dab864a2b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a15b5aae4d441d2bef678e30097c9cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"264c69508a8d4298bce090c9174e8fff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e12667650d654eaaa33028ae47aa981d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc76c50aed274d4c8145ee78ab434112"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6bbb01488b87454aaa6ea75fdd7defc5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3743f8ad1fce46da892b6e8d68799add"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f35107cea616441ea997776197bd8476"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"daecfe8ccb344ea8b964c5c83492d677"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfed8ce1c58a42b9b7721a00c1b25853"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5f8bb527b83413da636797ce22a79d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4aed831a46534a0eba6d03f0d0ae169b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8e3672b43ec4b55a693fac8ea3e7d31"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ed791ed52fa4a589023b94bc6395f51"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4afaf766a6348e9934deabf6280d8c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2b08f2981ca446ca591e09b7fb28031"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8094e601ed37437581a49736890fdef4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a3221db95584137b7697f89e6b700b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9febcd926bb47fbaef2f3a44531c27e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a7a5e8c1ae94d84b0baff1cf629c4f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0269c50735ab4bc49db9d594c30e71f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"886cb06deca1458dbd9c261b266b23b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10ed0704ff0749f18e9c5d8f5dd6d52c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"829b17e62ed84155856cae98ebbe8940"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63a5f2a2802d41cf99b8090bac520ef6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81df753f8461469e828d85bb68fc6bbc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"071c59c4e00441b599253c68cb2d923e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb00f21bdbf74b409adee7ce4a50a1cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2bda71c90bc248e5bb3ea87218816c29"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e37ef82f8f342119b38b87f4ab67dc6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e721bf1c1f541909ef2a449b9661188"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59447c5d8056457c8388f009f3301061"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9154ae6c2e0496f8692e7405f74912b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6720351d77114c1fb9ddf525475b7428"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"799ec4f459b0413890cbe1f1f9e85d57"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4f1ca8a055b419ea0bc9e299f51dff0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fb8b27c61dd4dfb95cc60a1ecd27f98"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ac9ee22c3674fe3a9ee563ba5bbccc6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa628b3c02ee4b7397179f47c3b50b78"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91cb3eed3b9b4e82adadda7ea25e9bcd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f78d217cf6a47f6a3289348df8177a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"939797dfe37a47b584822debb0933855"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f445c29cb9440d49e755e963e6b46f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3ec80b5812f423bb6332a89f097d621"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e387b2be5954d1c931be97a35d64088"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9152b19054054ec6bf027bd6fa693c7c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbcb76b0e5b2401d8215ce516562b072"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0b24a8bc6d74872bd4779733dd3e4b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46a40be1e6ac44c99e6bec8280511ada"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07b0f052b15b4907b0be8024db4e0780"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c29f39cf48d74070bc178e46b8f28f58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4fe10bce86c4f6d95f510e6d2247424"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d6827f333cc4eb782764a6c8c8626ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f476e606c33142d88beb50f5bd63f80c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba64802d4b704a9ea00c8a1d422adb84"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f08bf022b2d47309a738160702c7668"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"441a20d45a77496f86c85f4b1f2b91ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31fdc11d8e0e429387be18b2ef059511"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1dde238a48b40a985a0d48b6097db7d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1696a165647c4c689c277c04b5a3de4b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11be3b4a29854bc2a8ad821cc3bfa928"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"246aadf7a5f1427198fa95011fce3371"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc60f565760e491089246b280d0b9be6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2451d7f77e7041b3be2cccece68d8b4d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57ad0b4be21449caa6b778d12e0ee58d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cacca6e120234afa932f5645c168abc4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea2d203ae187431a8530d19ebbb21c5f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5164c4daeea4b01b9c96a33b88ecb3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46e9fd0d28564fa2bf02f9e1cb6e40f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c0895255e1d46da81f52bb79973598a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57d45fccdcc44dcab2388f7528442a1d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06315b4ed50942fcad27ffbdbbdb2210"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b0b54a5ead34a3680dea2f6db7b0058"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"addd0f6230e1405f9d2c25a25dc52b55"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a268f3a6a7f6480e934e09d049366b73"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8faf116468f1402caf000b7835a8adf2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31dfbbc076dc43b2bdcfcd2d041905cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"415dde7507a844c6ab7c10c50fb01abf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a8e5a82ec064edb904ebe2ff349a94b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"421aa72126d54589a0c5cd1d5e12874f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70a3b33401174e21a729f75eb831f698"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21eee896024a46c286fe3b8feeffb311"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff9dab93cf474069802496d31dca7cbe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0c72af8855b4b419ef31fc8bc693cbb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88424c6bbd7446f2a5b929f1ef9e2a2c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab24a6a3c20b4426bde1eaf644800342"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2dee02b75a2a49ab8d280a16b969ce28"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37b877785e7b4d7ca551b2df125f67f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88b07907dca247ae91a0476f08200d63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4396ecb3a1ae4e4a8ffebcbd0b36602d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53f969ca4c5f4457882f05b3598726f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a33b73ba1cb34ada90b414850d84971c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7cb1542d5cfb4c51a5d038f8fbb932f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9868ce3f417746368b8bca74b873c677"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84de1279e78744d5aae65ffdd6cfe7d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"050513ceb9cc4926a5b3fcc606762132"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4739ebda3d3c4dbcb410f0244e041463"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4c5e83bc6224b49b685be0a81804dcd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7700cdbaddf44b0597308aeb0b6b3f66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bee96500bf194b19a1669e2b1aa47913"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa39648e0bdd47c597bf0e4444b648dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f56dddc7f3d493996540884a6757d51"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f774e86b9da3415092799c1d2a67dc34"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbb739d1092a4e6a9f355a8c2bef9404"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ff9ff46d5c146978c3994fca943619d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4da9de923e47474e94186012b3370456"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ddb6711964974f928772292c59693e0c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a98b15230c754a4ca37f288dabcd12f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbc22261355942c993cd63d1e7400bb5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4e476f801044544a0533d2c3076419a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cff629ba665349d7bc4d2e793da011cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c078b4e5e164a91b48beef9b3e966c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5dd1ef8b1c5b42d296585cb2064d6013"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf6f8a82eefb4bd0a625e21012cc038d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0aa20ab16774aab99889e225ee75c65"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9075eef0dd6451b8128fa80f2e776dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62e149d8efb643ae8fb29dcdeea72e82"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e0e3db09dd14146ba4eb2042bc93e13"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a04232777e145a5ad49baaa203c163a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fe3c07a4158409788aa2335b566708f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a085f0c2cfa749b2b25ed11a2aafec4d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55e2545270a8484fb0b5f44068cf5894"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fcaa6a946174662b0fb8b61d3012355"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f258530154ed42998f184fcd591a5980"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65dbfbd1f83e4dc28150048f3cd51629"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2f64d5df0c941f1a69805f527db3e62"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90c9e49486cb4a01afeacaeee139119d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b620c8082b34b8eab7cf9444bd60a30"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"677a3613671742a6b3626a2f96e0d665"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac491306ef094f24afe46c8b39066438"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0c47305aa754ad7b40988113e4924d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c7dc1dbbc03402d875f29106ee504a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6088d763fea44d4971b6b6bf89a1449"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df29ad7d9f3c463faea0e7c2acdd577f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18e496169f074ae0b7b4c4a6e14e91a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"259290264d5545e283556db571a1ebaa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f18e2aa10d546879089f849866537fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d397e9ca7444410287221850320350e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"202cb5c3281641ccaec34687032ce51e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c392c5732f3408da70b9f44fe32213d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87232465a9994d7fa0d602b94c20aa2d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f72d9499e9364511be342302ae576f6d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9953fde306224787aec06f39988b7963"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e638b5f1a48d4b5a80d2b0680d707ab6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e709cca85ff48d2a27740730230f77e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d965ca26ec324772a865d15ca1fb217e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9264a70a2f5e42319415f5ece671bb3c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"738bd7f080eb49729aadb9c9adceac64"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd113534fb2b4c1090d6066edad86003"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee7c63930eeb4446900d7a32cdc68e0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c8c4d9d46634ef7b1302beef27c8591"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1dc3d7117e1e45f8b546a90f0fbd0ee9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"163a0089ee6d4be88c1f7317ff43ce27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b0d35688f9847e1b36869d567e0b362"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be8547e0034d44938650e90da9cd089b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"202abde1302a440da7dc8d2079a357c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f161f1cb195d488ab6c21f5707698ac5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a29ff5b4c6fe4d7db0f412cd88e5ddb9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"112f9ae118ca4139bdd0c0744b8c139c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfc3345c327c46018b43fd9eaf974dc5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c7ec82206654727a8bbe4242f394577"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c17a08d48ec4989a755af1af6f864e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87514c8148814bde8574bafb678a5d1a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de5981202a2a4876a8426146b1430a92"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"276a2391fb3c4f0da4644bd65a9a13ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"481660ba907d48a097436dbdabf50ee2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4894262dc909454baa9c6cd1233a2271"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"243030971cd4415d892ccad6e22dbe95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63e2436cf96f422b9661415b64b8373f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81ebf8a37dc44886937cdcae358c8ab9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9da838c770c6465cab69ec712ae0c760"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abe689aba08b4942ad35ce37cbed39bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"332cc99f9fb241cc83080ddf66b92db8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74da14f13b024b38ad28394e6bd278ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f537eb5e69a148e48b0b1bc19ce788fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17b64f5efa4d4648b5d890fb9d5d476c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b4f2ea3958f4a13b42094784e3ef489"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88c0d2dda12f4300a7bf507f2407c46d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ef248a7e723430d8f1974add1b32b94"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b89148d1f864a9fb401e7763ff35acc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56d4e9109d044305b139f0a75c677b7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b267c294f2ba42cc906b8c57dd28cce7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"981fca68ccc041b8b43bf2cb71d31884"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa1f1c7c1dc54d34ba8326abca045890"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"161de2b2b7c44f588310b2a3418635ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d365a362f80e45d3989719f9c504679a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80bcc264ceb24170a6906716e8bc75a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ffacb9c6dd649b6bcee051c14c9fa86"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da72b34fbbfd447aa8dac10a52b2ab11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae89489739c442d9ab9e745efbcfa5e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64c02a9ee5bc48d1a97705f68e3333ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd2f77d3316b45aea9c001511c456b9b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ad832bd9e9a4cd89c3febec4ff4f262"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c24ee6750147452ea41b81e098219c0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b2c51ddbc1740dab1c87c8fb03dcfff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d0c1827d5a94f42b5c9fe6dbd6076ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"666d6b3d4826459fb26267f8f0c0c482"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb0d709689894defb948dfddac549900"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2eeeedb61fc44b15a32f814949c0e74d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"768354c0b4994cd798fadbb7ed679727"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77d533539b6744e38673bcbafe749c63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"260f06b5992f49ec9037109c70d89674"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43643309f06e4d759d3e479335a41aa5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5bbf89bb477847bebc4742c25fc4e0e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bb7afc17aa246b6a8b7296760a444a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6f925fec8a641aaa51698d911919ce8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6cb8c5943a3403988198657689ce56a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b3f2181d1ae457f82012efd742ec35e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72615bd415f3432585b1446d7c7153d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9043b307d9c447ebaeadccbfba6fb77"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32f349f4cba64bb5a1e5fd0937c39791"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd8af646763344679a40e1c904f4e222"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d449906b70948deaa1b152482c5ae64"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da00e8e1be844ed5b3f1a9f0e9ae0478"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eebb6ce6e09d431c97a302f55d4c470a"}},"metadata":{}},{"name":"stdout","text":"\nSuccessfully created FAISS index with 1248 passages\nPassage is: <__main__.PassageRetriever object at 0x7ff26a289840>\nLoading question generation model...\nLoading tokenizer...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/33.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"463718a710144222bc7bad469c31f31f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffd7f0e477ed47be93feb4b94382fd07"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba02c3b2392c417b873c31f8828baba4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84422f2139d94838a9fd7765291806b1"}},"metadata":{}},{"name":"stdout","text":"Loading base model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/627 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"373933dd073e49028331a45e570a2ec8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/13.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be5ac432163244548e1d1e430e838ad1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3432a3063b914072ae36d5c30edfa1e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"018d3afa1097406aa80849fc0d4e19a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/67.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11d038d423514e979d43928014b4e069"}},"metadata":{}},{"name":"stderr","text":"`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\nGemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n`config.hidden_activation` if you want to override this behaviour.\nSee https://github.com/huggingface/transformers/pull/29402 for more details.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40da3793cdce4dd8928f8f2036d38563"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7eff08b17e2e48ad9de07e35a1feb52b"}},"metadata":{}},{"name":"stdout","text":"Loading fine-tuned adapter...\nModel loaded successfully!\nGenerating and evaluating questions...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"087dc841e5364a91aaeccb3e61776c48"}},"metadata":{}},{"name":"stderr","text":"Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n","output_type":"stream"},{"name":"stdout","text":"retrieved data is : {'passage': 'In Java, variables are used to store data values that can be manipulated and accessed throughout the program. To use a variable, it must first be declared and initialized. Declaration involves specifying the type of the variable, such as int, double, or String, followed by the variable name. Initialization is the process of assigning an initial value to the variable. This can be done at the time of declaration or later in the program. For example, int age; declares a variable named age of type int, while int age = 25; declares and initializes the variable with a value of 25. It is important to initialize variables before using them to avoid unexpected behavior in the program.', 'topic': 'Java Variables', 'subtopic': 'Variable Declaration and Initialization', 'difficulty': 'Easy', 'reference_questions': ['What is the purpose of declaring a variable in Java?', 'What is initialization in Java variable declaration?', 'Why is it important to initialize variables before using them in Java?']}\nGeneratedQuestion: Why is it important to initialize variables in Java?\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79925ab5bfba4e1e92bc31ab4ad123ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"adf66c2edb93410b9ff0a72b47f5d47f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6813fc4141254874a02c3e3eb861c79a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aea2be0c48144f39aec966859f891d89"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b6fb2f980254c64b99739a9398b4e13"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17e9bedcaf72409f8a161db3a2728105"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\nAverage Scores:\nBLEU-1: 0.0495\nBLEU-2: 0.0460\nBLEU-3: 0.0419\nBLEU-4: 0.0362\nBERTScore-P: 0.9377\nBERTScore-R: 0.8847\nBERTScore-F1: 0.9104\nROUGE-1: 0.4737\nROUGE-2: 0.4444\nROUGE-L: 0.4737\n\nScores by Difficulty:\n              BLEU-1    BLEU-2    BLEU-3    BLEU-4  BERTScore-P  BERTScore-R  \\\nDifficulty                                                                     \nEasy        0.049521  0.046036  0.041886  0.036207     0.937716     0.884664   \n\n            BERTScore-F1   ROUGE-1   ROUGE-2   ROUGE-L  \nDifficulty                                              \nEasy            0.910417  0.473684  0.444444  0.473684  \n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport faiss\nfrom sentence_transformers import SentenceTransformer\nimport torch\nimport json\nimport nltk\nfrom nltk.translate.bleu_score import sentence_bleu\nfrom bert_score import score\nfrom rouge_score import rouge_scorer\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nfrom peft import PeftModel, PeftConfig\nimport os\nfrom datetime import datetime\nimport logging\nfrom dataclasses import dataclass\nfrom typing import List, Dict, Tuple, Optional\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Gemini integration\nfrom langchain_google_genai import ChatGoogleGenerativeAI\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Download NLTK data\nnltk.download('punkt')\n\n@dataclass\nclass InterviewMetrics:\n    overall_score: float\n    topic_scores: Dict[str, float]\n    difficulty_scores: Dict[str, float]\n    topic_coverage: float\n    difficulty_progression: float\n    topic_progression: float\n    response_time_metrics: Dict[str, float]\n    confidence_scores: List[float]\n\n@dataclass\nclass InterviewAlgorithm:\n    topics: List[str]\n    difficulties: List[str]\n    \n    def __init__(self, topics: List[str], difficulties: List[str]):\n        self.topics = topics\n        self.difficulties = difficulties\n        self.topic_weights = {topic: 1.0 for topic in topics}\n        self.performance_threshold = {\n            'promotion': 0.75,\n            'demotion': 0.45,\n            'mastery': 0.85\n        }\n        \n    def update_topic_weights(self, topic_performances: Dict[str, float]):\n        for topic, performance in topic_performances.items():\n            if performance < self.performance_threshold['demotion']:\n                self.topic_weights[topic] *= 1.5\n            elif performance > self.performance_threshold['mastery']:\n                self.topic_weights[topic] *= 0.5\n                \n    def select_next_topic(self, covered_topics: set, topic_performances: Dict[str, float]) -> str:\n        uncovered_topics = set(self.topics) - covered_topics\n        \n        if uncovered_topics:\n            topic_weights = {\n                t: self.topic_weights[t] * 2.0 if t in uncovered_topics else self.topic_weights[t]\n                for t in self.topics\n            }\n        else:\n            topic_weights = {t: 1.0 / (perf + 0.1) for t, perf in topic_performances.items()}\n            \n        topics = list(topic_weights.keys())\n        weights = list(topic_weights.values())\n        return np.random.choice(topics, p=np.array(weights)/sum(weights))\n    \n    def determine_difficulty(self, current_difficulty: str, avg_performance: float) -> str:\n        diff_index = self.difficulties.index(current_difficulty)\n        \n        if avg_performance > self.performance_threshold['promotion'] and diff_index < len(self.difficulties) - 1:\n            return self.difficulties[diff_index + 1]\n        elif avg_performance < self.performance_threshold['demotion'] and diff_index > 0:\n            return self.difficulties[diff_index - 1]\n        return current_difficulty\n\nclass AdvancedInterviewSystem:\n    def __init__(self, access_token: str = None, adapter_path: str = None, google_api_key: str = None):\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        logger.info(f\"Using device: {self.device}\")\n        \n        self.access_token = access_token\n        self.adapter_path = adapter_path\n        \n        # Gemini configuration\n        os.environ[\"GOOGLE_API_KEY\"] = google_api_key or os.environ.get('GOOGLE_API_KEY')\n        self.gemini_llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.7)\n        \n        # Initialize models\n        self.model, self.tokenizer = self.load_fine_tuned_model()\n        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2').to(self.device)\n        \n        # Initialize evaluation metrics\n        self.rouge_scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n        \n        # Initialize data structures\n        self.index = None\n        self.passages = []\n        self.df = None\n        self.scaler = MinMaxScaler(feature_range=(0, 1))\n        \n        # Interview tracking\n        self.asked_questions = []\n        self.responses = []\n        self.response_times = []\n        self.topics_covered = set()\n        self.difficulty_history = []\n        self.topic_history = []\n        self.performance_history = []\n        self.confidence_scores = []\n        self.reference_answers = []\n        \n        self.difficulty_levels = {'Easy': 1, 'Medium': 2, 'Hard': 3}\n        self.interview_algorithm = None\n\n    def load_fine_tuned_model(self):\n        try:\n            base_model_name = \"google/gemma-2b\"\n            logger.info(\"Loading tokenizer...\")\n            tokenizer = AutoTokenizer.from_pretrained(base_model_name, use_auth_token=self.access_token)\n            \n            logger.info(\"Loading base model...\")\n            base_model = AutoModelForCausalLM.from_pretrained(\n                base_model_name,\n                torch_dtype=torch.float16,\n                device_map=\"auto\",\n                use_auth_token=self.access_token\n            )\n            \n            logger.info(\"Loading fine-tuned adapter...\")\n            model = PeftModel.from_pretrained(base_model, self.adapter_path)\n            logger.info(\"Model loaded successfully!\")\n            return model, tokenizer\n        except Exception as e:\n            logger.error(f\"Error loading model: {str(e)}\")\n            return None, None\n\n    def generate_gemini_reference_answer(self, passage: str, question: str) -> str:\n        \"\"\"\n        Generate a reference answer using Gemini\n        \"\"\"\n        try:\n            print(\"enters gemini\")\n            print(\"passage is\",passage)\n            print(\"question is:\",question)\n            prompt = f\"\"\"\n            Based on the following passage:\n            {passage}\n\n            Please generate a comprehensive answer to the question:\n            {question}\n\n            Provide a detailed, well-structured response that directly addresses the question.\n            \"\"\"\n            \n            response = self.gemini_llm.invoke(prompt)\n            print(\"response is:\",response)\n            return response.content\n        except Exception as e:\n            logger.error(f\"Error generating reference answer with Gemini: {str(e)}\")\n            return passage  # Fallback to original passage if Gemini fails\n\n    def load_dataset(self, csv_path: str):\n        try:\n            self.df = pd.read_csv(csv_path)\n            self.passages = self.df['Passage'].fillna('').tolist()\n            \n            embeddings = self.embedding_model.encode(self.passages, convert_to_tensor=True).cpu().numpy()\n            self.index = faiss.IndexFlatL2(embeddings.shape[1])\n            self.index.add(embeddings)\n            \n            self.topics = self.df['Topic'].unique().tolist()\n            self.subtopics = self.df['Sub-Topic'].unique().tolist()\n            \n            self.interview_algorithm = InterviewAlgorithm(\n                topics=self.topics,\n                difficulties=list(self.difficulty_levels.keys())\n            )\n            \n            logger.info(f\"Loaded {len(self.passages)} passages\")\n            logger.info(f\"Found {len(self.topics)} topics and {len(self.subtopics)} subtopics\")\n            \n        except Exception as e:\n            logger.error(f\"Error loading dataset: {str(e)}\")\n            raise\n\n    # Other methods like generate_question, evaluate_answer, etc. remain the same as in the previous implementation\n    def generate_question(self, passage: str, topic: str = None, subtopic: str = None, difficulty: str = None) -> str:\n        try:\n            prompt_parts = [\"Generate a question based on the following information:\"]\n            if topic:\n                prompt_parts.append(f\"Topic: {topic}\")\n            if subtopic:\n                prompt_parts.append(f\"Subtopic: {subtopic}\")\n            if difficulty:\n                prompt_parts.append(f\"Difficulty: {difficulty}\")\n            prompt_parts.append(f\"Passage: {passage}\")\n            prompt_parts.append(\"Question:\")\n            prompt = \"\\n\".join(prompt_parts)\n            \n            inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.device)\n            outputs = self.model.generate(\n                inputs[\"input_ids\"],\n                max_length=512,\n                temperature=0.7,\n                num_return_sequences=1,\n                do_sample=True,\n                top_p=0.9,\n                top_k=50\n            )\n            \n            question = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n            return question[len(prompt):].strip()\n        except Exception as e:\n            logger.error(f\"Error generating question: {str(e)}\")\n            return None\n\n    def evaluate_answer(self, question: str, user_answer: str, reference_answer: str, topic: str, difficulty: str) -> float:\n        try:\n            # Early detection of minimal or non-answers\n            minimal_responses = ['i don\\'t know', 'idk', 'dont know', 'not sure', '', 'no answer', 'none']\n            normalized_answer = user_answer.lower().strip()\n\n            if normalized_answer in minimal_responses:\n                logger.info(f\"Minimal response detected: {user_answer}\")\n                return 0.0\n\n            if len(normalized_answer) < 10:\n                logger.info(f\"Very short response detected: {user_answer}\")\n                return 10.0\n\n            # Using Gemini for evaluation\n            evaluation_prompt = f\"\"\"\n            Evaluate the following answer based on the given question and reference answer.\n\n            Question: {question}\n            Reference Answer: {reference_answer}\n            User Answer: {user_answer}\n\n            Score this answer from 0 to 100 based on:\n            1. Accuracy and correctness (40%)\n            2. Completeness of response (30%)\n            3. Clarity and structure (20%)\n            4. Technical depth appropriate for {difficulty} level (10%)\n\n            Return only a number between 0 and 100. For example: 75\n            \"\"\"\n\n            try:\n                response = self.gemini_llm.invoke(evaluation_prompt)\n                score_text = response.content.strip()\n                # Extract numeric score using regex\n                import re\n                score_match = re.search(r'\\d+(?:\\.\\d+)?', score_text)\n                if score_match:\n                    base_score = float(score_match.group())\n                else:\n                    base_score = 50.0  # Default score if parsing fails\n            except Exception as e:\n                logger.error(f\"Gemini evaluation failed: {str(e)}\")\n                base_score = 50.0  # Default fallback score\n\n            # Difficulty adjustment\n            difficulty_multipliers = {\n                'Easy': 1.0,\n                'Medium': 1.2,\n                'Hard': 1.5\n            }\n\n            # Apply difficulty multiplier\n            adjusted_score = base_score * difficulty_multipliers.get(difficulty, 1.0)\n\n            # Calculate confidence score\n            confidence_score = self.calculate_confidence_score(user_answer)\n\n            # Apply confidence adjustment (smaller impact)\n            final_score = adjusted_score * (0.9 + 0.1 * confidence_score)\n\n            # Ensure score is within 0-100 range\n            final_score = max(0, min(final_score, 100))\n\n            # Add confidence score to tracking\n            self.confidence_scores.append(confidence_score)\n\n            return final_score\n\n        except Exception as e:\n            logger.error(f\"Error in answer evaluation: {str(e)}\")\n            return 50.0  # Return middle score instead of 0 for unexpected errors\n\n           \n    def _assess_content_relevance(self, question: str, user_answer: str, reference_answer: str) -> float:\n        try:\n            # For very short or non-answers\n            if len(user_answer.strip()) < 10:\n                return 0.0\n\n            prompt = f\"\"\"\n            Strictly evaluate the content relevance of the following answer to the question:\n\n            Question: {question}\n            Reference Answer: {reference_answer}\n            User Answer: {user_answer}\n\n            If the user's answer shows absolutely no understanding or is completely off-topic, provide a score of 0.\n            If the user acknowledges not knowing or provides minimal information, provide a very low score between 0.05 and 0.2.\n            Otherwise, provide a score from 0 to 1 indicating how well the answer addresses the question.\n\n            Provide ONLY a numerical score between 0 and 1.\n            \"\"\"\n\n            response = self.gemini_llm.invoke(prompt)\n            relevance_score = float(response.content.strip())\n            return relevance_score\n        except Exception as e:\n            logger.warning(f\"Gemini relevance assessment failed: {e}\")\n            return 0.0  # Very low score if assessment fails\n\n    def _assess_technical_depth(self, user_answer: str, reference_answer: str, difficulty: str) -> float:\n        \"\"\"\n        Assess the technical depth of the answer based on difficulty level\n        \"\"\"\n        try:\n            prompt = f\"\"\"\n            Evaluate the technical depth of the following answer:\n\n            Reference Answer: {reference_answer}\n            User Answer: {user_answer}\n            Expected Difficulty: {difficulty}\n\n            Assess the answer's technical depth considering:\n            1. Complexity of explanation\n            2. Use of technical terminology\n            3. Depth of understanding demonstrated\n            4. Alignment with difficulty level\n\n            Provide a score from 0 to 1.\n            \"\"\"\n\n            response = self.gemini_llm.invoke(prompt)\n            depth_score = float(response.content.strip())\n            return depth_score\n        except Exception as e:\n            logger.warning(f\"Technical depth assessment failed: {e}\")\n            return 0.5\n\n    def _evaluate_domain_knowledge(self, user_answer: str, topic: str) -> float:\n        \"\"\"\n        Assess domain-specific knowledge\n        \"\"\"\n        try:\n            prompt = f\"\"\"\n            Evaluate the domain knowledge in the following answer for the topic {topic}:\n\n            User Answer: {user_answer}\n\n            Assess based on:\n            1. Accuracy of domain-specific information\n            2. Depth of understanding\n            3. Use of relevant terminology\n            4. Demonstration of expertise\n\n            Provide a score from 0 to 1.\n            \"\"\"\n\n            response = self.gemini_llm.invoke(prompt)\n            domain_score = float(response.content.strip())\n            return domain_score\n        except Exception as e:\n            logger.warning(f\"Domain knowledge assessment failed: {e}\")\n            return 0.5\n\n    def _assess_communication_quality(self, user_answer: str) -> float:\n        \"\"\"\n        Evaluate communication skills\n        \"\"\"\n        try:\n            # Check for:\n            # 1. Clarity\n            # 2. Conciseness\n            # 3. Structure\n            # 4. Grammar and language quality\n            communication_metrics = {\n                'clarity_score': self._assess_clarity(user_answer),\n                'conciseness_score': self._check_conciseness(user_answer),\n                'grammatical_score': self._evaluate_grammar(user_answer)\n            }\n\n            return np.mean(list(communication_metrics.values()))\n        except Exception as e:\n            logger.warning(f\"Communication quality assessment failed: {e}\")\n            return 0.5\n\n    def _evaluate_answer_structure(self, user_answer: str) -> float:\n        \"\"\"\n        Check the structure and organization of the answer\n        \"\"\"\n        try:\n            prompt = f\"\"\"\n            Evaluate the structure of the following answer:\n\n            {user_answer}\n\n            Assess based on:\n            1. Logical flow\n            2. Clear introduction\n            3. Well-organized points\n            4. Coherent conclusion\n\n            Provide a score from 0 to 1.\n            \"\"\"\n\n            response = self.gemini_llm.invoke(prompt)\n            structure_score = float(response.content.strip())\n            return structure_score\n        except Exception as e:\n            logger.warning(f\"Answer structure evaluation failed: {e}\")\n            return 0.5\n\n    def _check_contextual_understanding(self, question: str, user_answer: str) -> float:\n        \"\"\"\n        Assess the contextual understanding of the question\n        \"\"\"\n        try:\n            prompt = f\"\"\"\n            Evaluate the contextual understanding in this answer:\n\n            Question: {question}\n            Answer: {user_answer}\n\n            Assess:\n            1. Comprehension of question context\n            2. Addressing implicit aspects of the question\n            3. Showing deeper understanding beyond literal interpretation\n\n            Provide a score from 0 to 1.\n            \"\"\"\n\n            response = self.gemini_llm.invoke(prompt)\n            context_score = float(response.content.strip())\n            return context_score\n        except Exception as e:\n            logger.warning(f\"Contextual understanding assessment failed: {e}\")\n            return 0.5\n\n    def _calculate_advanced_nlp_metrics(self, user_answer: str, reference_answer: str) -> float:\n        \"\"\"\n        Calculate advanced NLP metrics\n        \"\"\"\n        try:\n            # BLEU score\n            bleu_score = sentence_bleu([reference_answer.split()], user_answer.split())\n\n            # BERT score\n            _, _, bert_f1 = score([user_answer], [reference_answer], lang='en', verbose=False)\n            bert_score = bert_f1.mean().item()\n\n            # ROUGE scores\n            rouge_scores = self.rouge_scorer.score(user_answer, reference_answer)\n            rouge_f1 = np.mean([\n                rouge_scores['rouge1'].fmeasure,\n                rouge_scores['rouge2'].fmeasure,\n                rouge_scores['rougeL'].fmeasure\n            ])\n\n            # Combine NLP metrics\n            nlp_score = (0.3 * bleu_score + 0.4 * bert_score + 0.3 * rouge_f1)\n            return nlp_score\n        except Exception as e:\n            logger.warning(f\"Advanced NLP metrics calculation failed: {e}\")\n            return 0.5\n\n    def calculate_confidence_score(self, answer: str) -> float:\n        hesitation_words = ['maybe', 'perhaps', 'probably', 'might', 'not sure']\n        confident_words = ['definitely', 'certainly', 'clearly', 'indeed', 'absolutely']\n        \n        answer_lower = answer.lower()\n        hesitation_count = sum(word in answer_lower for word in hesitation_words)\n        confidence_count = sum(word in answer_lower for word in confident_words)\n        \n        confidence_score = 0.5 + (confidence_count * 0.1) - (hesitation_count * 0.1)\n        return max(0, min(1, confidence_score))\n\n    def select_next_question(self) -> Tuple[str, str, str, str]:\n        if not self.asked_questions:\n            # First question: Use initial sampling strategy\n            row = self.df[self.df['Difficulty'] == 'Easy'].sample(n=1).iloc[0]\n            print(row)\n            return row['Topic'], row['Sub-Topic'], row['Passage'], 'Easy'\n        \n        # Calculate performance metrics\n        recent_window = min(5, len(self.performance_history))\n        print(recent_window)\n        avg_performance = np.mean(self.performance_history[-recent_window:])\n        print(avg_performance)\n        topic_performances = self.calculate_topic_wise_performance()\n\n        # Update topic weights in the interview algorithm\n        self.interview_algorithm.update_topic_weights(topic_performances)\n\n        # Select next topic using the interview algorithm\n        next_topic = self.interview_algorithm.select_next_topic(\n            self.topics_covered,\n            topic_performances\n        )\n\n        # Determine next difficulty level\n        current_difficulty = self.difficulty_history[-1] if self.difficulty_history else 'Easy'\n        next_difficulty = self.interview_algorithm.determine_difficulty(\n            current_difficulty,\n            avg_performance\n        )\n\n        # Use last response or last question to perform semantic search\n        if self.responses:\n            last_response = self.responses[-1]\n        else:\n            last_response = self.asked_questions[-1]\n\n        # Perform semantic search to find the most relevant passage\n        query_embedding = self.embedding_model.encode(last_response, convert_to_tensor=True).cpu().numpy()\n\n        # Search in the FAISS index\n        distances, indices = self.index.search(query_embedding.reshape(1, -1), k=10)\n\n        # Filter passages based on next_topic and next_difficulty\n        relevant_passages = []\n        for idx in indices[0]:\n            row = self.df.iloc[idx]\n            if row['Topic'] == next_topic and row['Difficulty'] == next_difficulty:\n                relevant_passages.append(row)\n\n        # If no passages match both topic and difficulty, try relaxing the constraints\n        if not relevant_passages:\n            for idx in indices[0]:\n                row = self.df.iloc[idx]\n                if row['Topic'] == next_topic:\n                    relevant_passages.append(row)\n\n        # If still no passages, fallback to sampling\n        if not relevant_passages:\n            mask = (self.df['Topic'] == next_topic)\n            row = self.df[mask].sample(n=1).iloc[0]\n        else:\n            # Select a random passage from the relevant set\n            row = relevant_passages[np.random.randint(len(relevant_passages))]\n\n        return row['Topic'], row['Sub-Topic'], row['Passage'], row['Difficulty']\n\n    def calculate_metrics(self) -> InterviewMetrics:\n        try:\n            print(\"hi\")\n            overall_score = np.mean(self.performance_history) if self.performance_history else 0\n            print(\"overall score is\",overall_score)\n            topic_scores = self.calculate_topic_wise_performance()\n            difficulty_scores = self.calculate_difficulty_wise_performance()\n            \n            topic_coverage = len(self.topics_covered) / len(self.topics)\n            difficulty_progression = self._calculate_difficulty_progression()\n            topic_progression = self._calculate_topic_progression()\n            print(\"topic progression is:\",topic_progression)\n            response_time_metrics = {\n                'average': np.mean(self.response_times),\n                'min': np.min(self.response_times),\n                'max': np.max(self.response_times),\n                'std': np.std(self.response_times)\n            }\n            \n            return InterviewMetrics(\n                overall_score=overall_score,\n                topic_scores=topic_scores,\n                difficulty_scores=difficulty_scores,\n                topic_coverage=topic_coverage,\n                difficulty_progression=difficulty_progression,\n                topic_progression=topic_progression,\n                response_time_metrics=response_time_metrics,\n                confidence_scores=self.confidence_scores\n            )\n        except Exception as e:\n            logger.error(f\"Error calculating metrics: {str(e)}\")\n            raise\n\n    def calculate_topic_wise_performance(self) -> Dict[str, float]:\n        topic_scores = {}\n        for topic, score in zip(self.topic_history, self.performance_history):\n            if topic not in topic_scores:\n                topic_scores[topic] = []\n            topic_scores[topic].append(score)\n        \n        return {\n            topic: np.average(scores, weights=np.linspace(1, 2, len(scores)))\n            for topic, scores in topic_scores.items()\n        }\n\n    def calculate_difficulty_wise_performance(self) -> Dict[str, float]:\n        diff_scores = {}\n        for diff, score in zip(self.difficulty_history, self.performance_history):\n            if diff not in diff_scores:\n                diff_scores[diff] = []\n            diff_scores[diff].append(score)\n\n        return {\n            diff: np.mean(scores) / self.difficulty_levels[diff]\n            for diff, scores in diff_scores.items()\n        }\n\n    def _calculate_difficulty_progression(self) -> float:\n        if len(self.difficulty_history) < 2:\n            return 1.0\n        correct_progressions = 0\n        total_transitions = len(self.difficulty_history) - 1\n        \n        for i in range(total_transitions):\n            current_level = self.difficulty_levels[self.difficulty_history[i]]\n            next_level = self.difficulty_levels[self.difficulty_history[i + 1]]\n            current_performance = self.performance_history[i]\n            \n            if (current_performance > 0.8 and next_level >= current_level) or \\\n               (current_performance < 0.4 and next_level <= current_level) or \\\n               (0.4 <= current_performance <= 0.8 and next_level == current_level):\n                correct_progressions += 1\n                \n        return correct_progressions / total_transitions\n\n    def _calculate_topic_progression(self) -> float:\n        if len(self.topic_history) < 2:\n            return 1.0\n        correct_progressions = 0\n        total_transitions = len(self.topic_history) - 1\n        covered_topics = set()\n        \n        for i in range(total_transitions):\n            current_topic = self.topic_history[i]\n            covered_topics.add(current_topic)\n            if self.performance_history[i] > 0.7 and self.topic_history[i + 1] not in covered_topics:\n                correct_progressions += 1\n            elif self.performance_history[i] < 0.5 and self.topic_history[i + 1] in covered_topics:\n                correct_progressions += 1\n                \n        return correct_progressions / total_transitions\n    \n    def save_interview_report(self, file_path: str = \"/kaggle/working/interview_report.md\"):\n        print(\"enters saving mode\")\n        metrics = self.calculate_metrics()\n        print(\"metrics are:\",metrics)\n        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n        \n        with open(file_path, \"w\") as f:\n            f.write(f\"# Interview Report - {timestamp}\\n\\n\")\n            f.write(\"## Overall Performance\\n\")\n            f.write(f\"- Overall Score: {metrics.overall_score:.2f}%\\n\")\n            f.write(f\"- Topic Coverage: {metrics.topic_coverage:.2f}%\\n\")\n            f.write(f\"- Difficulty Progression Score: {metrics.difficulty_progression:.2f}\\n\")\n            f.write(f\"- Topic Progression Score: {metrics.topic_progression:.2f}\\n\\n\")\n            \n            f.write(\"## Topic-wise Performance\\n\")\n            for topic, score in metrics.topic_scores.items():\n                f.write(f\"- {topic}: {score:.2f}%\\n\")\n            f.write(\"\\n\")\n            \n            f.write(\"## Difficulty-wise Performance\\n\")\n            for diff, score in metrics.difficulty_scores.items():\n                f.write(f\"- {diff}: {score:.2f}%\\n\")\n            f.write(\"\\n\")\n            \n            f.write(\"## Response Time Analysis\\n\")\n            f.write(f\"- Average Response Time: {metrics.response_time_metrics['average']:.2f} seconds\\n\")\n            f.write(f\"- Minimum Response Time: {metrics.response_time_metrics['min']:.2f} seconds\\n\")\n            f.write(f\"- Maximum Response Time: {metrics.response_time_metrics['max']:.2f} seconds\\n\")\n            f.write(f\"- Response Time Standard Deviation: {metrics.response_time_metrics['std']:.2f} seconds\\n\\n\")\n            \n            f.write(\"## Confidence Analysis\\n\")\n            f.write(f\"- Average Confidence Score: {np.mean(metrics.confidence_scores):.2f}\\n\")\n            f.write(f\"- Confidence Score Trend: {self._calculate_confidence_trend(metrics.confidence_scores)}\\n\\n\")\n            \n            f.write(\"## Question History\\n\")\n            for i, (q, r, t, d, p, ref) in enumerate(zip(\n                self.asked_questions,\n                self.responses,\n                self.topic_history,\n                self.difficulty_history,\n                self.performance_history,\n                self.reference_answers\n            ), 1):\n                f.write(f\"\\n### Question {i}\\n\")\n                f.write(f\"- Topic: {t}\\n\")\n                f.write(f\"- Difficulty: {d}\\n\")\n                f.write(f\"- Question: {q}\\n\")\n                f.write(f\"- Response: {r}\\n\")\n                f.write(f\"- Reference Answer: {ref}\\n\")\n                f.write(f\"- Performance Score: {p:.2f}%\\n\")\n            \n            # Generate and save performance visualization\n            self._generate_performance_plots()\n            f.write(\"\\n## Performance Visualizations\\n\")\n            f.write(\"- Performance trends visualization has been saved as 'performance_trends.png'\\n\")\n        \n        logger.info(f\"Interview report saved to {file_path}\")\n\n    def _calculate_confidence_trend(self, confidence_scores: List[float]) -> str:\n        if len(confidence_scores) < 2:\n            return \"Insufficient data\"\n        \n        slope = np.polyfit(range(len(confidence_scores)), confidence_scores, 1)[0]\n        if slope > 0.05:\n            return \"Increasing\"\n        elif slope < -0.05:\n            return \"Decreasing\"\n        else:\n            return \"Stable\"\n\n    def _generate_performance_plots(self):\n        plt.figure(figsize=(15, 10))\n        \n        # Performance over time\n        plt.subplot(2, 2, 1)\n        plt.plot(self.performance_history, marker='o')\n        plt.title('Performance Over Time')\n        plt.xlabel('Question Number')\n        plt.ylabel('Score (%)')\n        \n        # Difficulty progression\n        plt.subplot(2, 2, 2)\n        difficulty_values = [self.difficulty_levels[d] for d in self.difficulty_history]\n        plt.plot(difficulty_values, marker='s')\n        plt.title('Difficulty Progression')\n        plt.xlabel('Question Number')\n        plt.ylabel('Difficulty Level')\n        plt.yticks([1, 2, 3], ['Easy', 'Medium', 'Hard'])\n        \n        # Topic coverage\n        plt.subplot(2, 2, 3)\n        topic_counts = pd.Series(self.topic_history).value_counts()\n        topic_counts.plot(kind='bar')\n        plt.title('Topic Coverage')\n        plt.xlabel('Topics')\n        plt.ylabel('Number of Questions')\n        plt.xticks(rotation=45)\n        \n        # Confidence trend\n        plt.subplot(2, 2, 4)\n        plt.plot(self.confidence_scores, marker='o')\n        plt.title('Confidence Trend')\n        plt.xlabel('Question Number')\n        plt.ylabel('Confidence Score')\n        \n        plt.tight_layout()\n        plt.savefig('/kaggle/working/performance_trends.png')\n        plt.close()\n\ndef main():\n    # Configure logging\n    logging.basicConfig(level=logging.INFO)\n    logger = logging.getLogger(__name__)\n\n    # Configuration\n    try:\n        # Option 1: Use environment variables or default paths\n        csv_path = os.environ.get('DATASET_PATH', '/kaggle/input/nikahatmaam/pass_QA_topic_stopic_diff.csv')\n        adapter_path = os.environ.get('ADAPTER_PATH', '/kaggle/input/config-files')\n        access_token = \"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\"\n        google_api_key = \"AIzaSyC29gObkycJDBjVkEWjhJoJO-HVB0pC00E\"\n\n        # Option 2: Prompt user for inputs or use defaults\n        if not csv_path or not os.path.exists(csv_path):\n            csv_path = input(\"Enter the path to your interview dataset CSV (default: './dataset.csv'): \") or './dataset.csv'\n        \n        if not adapter_path or not os.path.exists(adapter_path):\n            adapter_path = input(\"Enter the path to your model adapter (default: './adapter'): \") or './adapter'\n        \n        if not access_token:\n            access_token = input(\"Enter your Hugging Face access token (optional, press enter to skip): \") or None\n\n        if not google_api_key:\n            google_api_key = input(\"Enter your Google API key: \")\n\n        # Initialize the interview system\n        interview_system = AdvancedInterviewSystem(\n            access_token=access_token, \n            adapter_path=adapter_path,\n            google_api_key=google_api_key\n        )\n        \n        # Load the dataset\n        interview_system.load_dataset(csv_path)\n        logger.info(\"Dataset loaded successfully\")\n        print(\"Dataset succesfully loaded\")\n        # Conduct interview\n        num_questions = int(input(\"How many questions do you want in the interview? (default is 10): \") or 10)\n        \n        for _ in tqdm(range(num_questions), desc=\"Conducting interview\"):\n            # Select next question\n            topic, subtopic, passage, difficulty = interview_system.select_next_question()\n            \n            # Generate question\n            if interview_system.model and interview_system.tokenizer:\n                question = interview_system.generate_question(passage, topic, subtopic, difficulty)\n            else:\n                # Fallback to a simple question generation if no model is available\n                question = f\"Tell me about {topic} in the context of {subtopic}\"\n            \n            # Prompt user for response\n            print(f\"\\nQuestion (Difficulty: {difficulty}, Topic: {topic}): {question}\")\n            user_response = input(\"Your response: \")\n            \n            # Evaluate response\n            reference_answer = interview_system.generate_gemini_reference_answer(passage, question)\n#             print(\"reference answer is:\", reference_answer)\n            performance = interview_system.evaluate_answer(\n                question,          # Question\n                user_response,     # User response\n                reference_answer,  # Reference answer\n                topic,             # Topic\n                difficulty         # Difficulty\n            )\n            \n            print(\"performance is:\",performance)\n            # Track interview progress\n            interview_system.asked_questions.append(question)\n            interview_system.responses.append(user_response)\n            interview_system.reference_answers.append(reference_answer)\n            interview_system.topic_history.append(topic)\n            interview_system.difficulty_history.append(difficulty)\n            interview_system.performance_history.append(performance)\n        \n        # Generate and save interview report\n        interview_system.save_interview_report()\n        logger.info(\"Interview completed. Report generated successfully.\")\n    \n    except Exception as e:\n        logger.error(f\"An error occurred during the interview: {str(e)}\")\n        logger.exception(e)\n\nif __name__ == \"__main__\":\n    main()","metadata":{"execution":{"iopub.status.busy":"2024-11-20T16:38:44.361508Z","iopub.execute_input":"2024-11-20T16:38:44.361787Z","iopub.status.idle":"2024-11-20T16:40:01.737334Z","shell.execute_reply.started":"2024-11-20T16:38:44.361760Z","shell.execute_reply":"2024-11-20T16:40:01.736493Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6b3631bfa0d4deabc0a55b245b00906"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/40 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7c766de7cea456985bdb4f90f12559e"}},"metadata":{}},{"name":"stdout","text":"Dataset succesfully loaded\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"How many questions do you want in the interview? (default is 10):  2\n"},{"name":"stderr","text":"Conducting interview:   0%|          | 0/2 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Unnamed: 0                                                  957\nID                                                          958\nTopic                                       Java Multithreading\nSub-Topic                       Introduction to Multithreading:\nPassage       Multithreading is a powerful concept in Java t...\nDifficulty                                                 Easy\nQuestion                        What is multithreading in Java?\nAnswer        Multithreading in Java allows concurrent execu...\nName: 957, dtype: object\n\nQuestion (Difficulty: Easy, Topic: Java Multithreading): How can multithreading help in improving the performance of a program?\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Your response:  Multithreading improves program performance by allowing multiple tasks to execute concurrently within a single process\n"},{"name":"stdout","text":"enters gemini\npassage is Multithreading is a powerful concept in Java that allows concurrent execution of multiple threads within a single program. It enables developers to write efficient and responsive applications by dividing tasks into smaller units of execution that can run simultaneously. By utilizing multiple threads, a program can make better use of available system resources and improve overall performance. In Java, multithreading is achieved by extending the Thread class or implementing the Runnable interface. Threads can be created, started, paused, resumed, and terminated, providing a high level of control over the execution flow. However, multithreading also introduces challenges such as thread synchronization, resource sharing, and deadlock prevention, which need to be carefully addressed to ensure the correctness and reliability of the application.\nquestion is: How can multithreading help in improving the performance of a program?\nresponse is: content='Multithreading significantly enhances program performance by enabling concurrent execution of multiple threads within a single program. Through multithreading, a program can divide its tasks into smaller, independent units that can be executed simultaneously. This approach has several key benefits:\\n\\n1. **Increased Concurrency:** Multithreading allows multiple tasks to execute concurrently, increasing the overall throughput of the program. By utilizing multiple threads, the program can make better use of available system resources, such as multiple CPU cores, leading to improved performance.\\n\\n2. **Improved Responsiveness:** Multithreading enables a program to respond to events or user interactions in a more timely manner. While one thread is performing a time-consuming task, other threads can continue to execute, ensuring that the application remains responsive and interactive.\\n\\n3. **Efficient Resource Utilization:** Multithreading helps optimize the utilization of system resources. By dividing tasks into smaller units, the program can execute them in parallel, reducing the overall execution time and improving resource efficiency.\\n\\n4. **Scalability:** Multithreaded programs are inherently scalable, as they can easily adapt to changes in the number of available system resources. By creating additional threads when more resources become available, the program can take advantage of the increased capacity and further improve performance.\\n\\n5. **Reduced Execution Time:** By executing tasks concurrently, multithreading reduces the overall execution time of the program. This is particularly beneficial for computationally intensive tasks that can be broken down into smaller, independent units.\\n\\nOverall, multithreading is a powerful technique that can significantly improve the performance of a program by enabling concurrent execution, increasing responsiveness, optimizing resource utilization, enhancing scalability, and reducing execution time.' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]} id='run-7acf5457-9240-4ffa-8df8-1c1ec8ea1dbd-0' usage_metadata={'input_tokens': 195, 'output_tokens': 328, 'total_tokens': 523, 'input_token_details': {'cache_read': 0}}\n","output_type":"stream"},{"name":"stderr","text":"Conducting interview:  50%|     | 1/2 [00:28<00:28, 28.27s/it]","output_type":"stream"},{"name":"stdout","text":"performance is: 66.5\n1\n66.5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1662b9e3148341ffa8a1ffaad81fc54a"}},"metadata":{}},{"name":"stdout","text":"\nQuestion (Difficulty: Easy, Topic: Java Abstraction): How does encapsulation contribute to creating modular and maintainable code in Java?\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Your response:  java is idiot\n"},{"name":"stdout","text":"enters gemini\npassage is Encapsulation is another important concept in Java that complements abstraction. It involves bundling data and methods together into a single unit called a class. Encapsulation provides data hiding and protects the internal state of an object from external access. By using encapsulation, we can control how the data is accessed and modified, ensuring data integrity and security. Abstraction, on the other hand, focuses on hiding unnecessary details and providing a simplified view of an object. Together, encapsulation and abstraction help in creating modular and maintainable code by separating the implementation details from the external interface.\nquestion is: How does encapsulation contribute to creating modular and maintainable code in Java?\nresponse is: content=\"**Encapsulation's Contribution to Modular and Maintainable Code in Java**\\n\\nEncapsulation, a fundamental concept in Java, plays a vital role in fostering the development of modular and maintainable code. It involves the bundling of data and methods together into a cohesive unit known as a class. Through encapsulation, Java achieves data hiding and safeguards the internal state of an object from unauthorized access.\\n\\nBy controlling the access to and modification of data, encapsulation ensures data integrity and security. This is achieved by restricting direct access to the object's internal state and providing controlled access through well-defined methods. This approach allows for greater flexibility in modifying the implementation details of the class without affecting the external interface, thereby promoting modularity.\\n\\nFurthermore, encapsulation enhances code maintainability by promoting the separation of concerns. By allowing classes to be designed around specific functionalities, encapsulation enables the creation of self-contained units of code that can be easily understood, modified, and reused. This modular approach reduces code complexity, making it easier to debug and maintain over time.\\n\\nIn summary, encapsulation in Java contributes to creating modular and maintainable code by:\\n\\n* **Enforcing data hiding:** Protecting the internal state of objects from unauthorized access.\\n* **Controlling data access and modification:** Ensuring data integrity and security through controlled methods.\\n* **Promoting modularity:** Encouraging the separation of concerns and self-contained units of code.\\n* **Enhancing maintainability:** Simplifying code understanding, modification, and reuse.\" additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]} id='run-3bb814d5-dc5e-4632-9fec-98ee54beabf1-0' usage_metadata={'input_tokens': 166, 'output_tokens': 301, 'total_tokens': 467, 'input_token_details': {'cache_read': 0}}\n","output_type":"stream"},{"name":"stderr","text":"Conducting interview: 100%|| 2/2 [00:47<00:00, 23.95s/it]","output_type":"stream"},{"name":"stdout","text":"performance is: 0\nenters saving mode\nhi\noverall score is 33.25\ntopic progression is: 1.0\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]}]}